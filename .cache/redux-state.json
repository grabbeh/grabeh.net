{
  "nodes": {
    "SitePage /dev-404-page/": {
      "path": "/dev-404-page/",
      "id": "SitePage /dev-404-page/",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "f91d29e10ba680b413138cf9ed86e655",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin dev-404-page": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/dev-404-page",
      "id": "Plugin dev-404-page",
      "name": "dev-404-page",
      "version": "1.0.0",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "createPagesStatefully"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/dev-404-page",
      "packageJson": {
        "name": "dev-404-page",
        "description": "Internal plugin to add a 404 page in development with helpful information",
        "version": "1.0.0",
        "main": "index.js",
        "author": "Kyle Mathews <mathews.kyle@gmail.com>",
        "license": "MIT",
        "dependencies": [],
        "devDependencies": [],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "caad47df99aae59f5afbea64a68e65f3",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin component-page-creator": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/component-page-creator",
      "id": "Plugin component-page-creator",
      "name": "component-page-creator",
      "version": "1.0.0",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "createPagesStatefully"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/component-page-creator",
      "packageJson": {
        "name": "component-page-creator",
        "description": "An internal Gatsby plugin that creates pages from component files in src/pages",
        "version": "1.0.0",
        "main": "index.js",
        "keywords": [
          "gatsby",
          "gatsby-plugin"
        ],
        "author": "Kyle Mathews <mathews.kyle@gmail.com>",
        "license": "MIT",
        "dependencies": [],
        "devDependencies": [],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "7806b68becbd872cdfd4e1311660aaa7",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin component-layout-creator": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/component-layout-creator",
      "id": "Plugin component-layout-creator",
      "name": "component-layout-creator",
      "version": "1.0.0",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "createLayouts"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/component-layout-creator",
      "packageJson": {
        "name": "component-layout-creator",
        "description": "An internal Gatsby plugin that creates pages from component files in src/layouts",
        "version": "1.0.0",
        "main": "index.js",
        "keywords": [
          "gatsby",
          "gatsby-plugin"
        ],
        "author": "Kyle Mathews <mathews.kyle@gmail.com>",
        "license": "MIT",
        "dependencies": [],
        "devDependencies": [],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "4629d49a4eb14ec2fb53d42c5ad2f444",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin internal-data-bridge": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/internal-data-bridge",
      "id": "Plugin internal-data-bridge",
      "name": "internal-data-bridge",
      "version": "1.0.0",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "sourceNodes",
        "onCreatePage"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/internal-data-bridge",
      "packageJson": {
        "name": "internal-data-bridge",
        "description": "An internal Gatsby plugin which creates data nodes from internal data",
        "version": "1.0.0",
        "main": "index.js",
        "author": "Kyle Mathews <mathews.kyle@gmail.com>",
        "license": "MIT",
        "dependencies": [],
        "devDependencies": [],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "3d82fcc16f2cb8387a24ac6a61497a8a",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin prod-404": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/prod-404",
      "id": "Plugin prod-404",
      "name": "prod-404",
      "version": "1.0.0",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "onCreatePage"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/prod-404",
      "packageJson": {
        "name": "prod-404",
        "description": "Internal plugin to detect various flavors of 404 pages and ensure there's a 404.html path created as well to ensure compatability with static hosts",
        "version": "1.0.0",
        "main": "index.js",
        "author": "Kyle Mathews <mathews.kyle@gmail.com>",
        "license": "MIT",
        "dependencies": [],
        "devDependencies": [],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "dacf71a085774190dd7cfa242055767b",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin query-runner": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/query-runner",
      "id": "Plugin query-runner",
      "name": "query-runner",
      "version": "1.0.0",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "onCreatePage",
        "onCreateLayout"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby/dist/internal-plugins/query-runner",
      "packageJson": {
        "name": "query-runner",
        "description": "Internal plugin for running queries",
        "version": "1.0.0",
        "main": "index.js",
        "author": "",
        "license": "MIT",
        "dependencies": [],
        "devDependencies": [],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "1608326c6df650cc39f3101a37188944",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin gatsby-source-filesystem": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby-source-filesystem",
      "id": "Plugin gatsby-source-filesystem",
      "name": "gatsby-source-filesystem",
      "version": "1.5.38",
      "pluginOptions": {
        "plugins": [],
        "path": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
        "name": "markdown-pages"
      },
      "nodeAPIs": [
        "sourceNodes",
        "setFieldsOnGraphQLNodeType"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby-source-filesystem",
      "packageJson": {
        "name": "gatsby-source-filesystem",
        "description": "Gatsby plugin which parses files within a directory for further parsing by other plugins",
        "version": "1.5.38",
        "keywords": [
          "gatsby",
          "gatsby-plugin"
        ],
        "author": {
          "name": "Kyle Mathews",
          "email": "mathews.kyle@gmail.com"
        },
        "license": "MIT",
        "dependencies": [
          {
            "name": "babel-cli",
            "version": "^6.26.0"
          },
          {
            "name": "babel-runtime",
            "version": "^6.26.0"
          },
          {
            "name": "better-queue",
            "version": "^3.8.7"
          },
          {
            "name": "bluebird",
            "version": "^3.5.0"
          },
          {
            "name": "chokidar",
            "version": "^1.7.0"
          },
          {
            "name": "fs-extra",
            "version": "^4.0.1"
          },
          {
            "name": "got",
            "version": "^7.1.0"
          },
          {
            "name": "md5-file",
            "version": "^3.1.1"
          },
          {
            "name": "mime",
            "version": "^1.3.6"
          },
          {
            "name": "pretty-bytes",
            "version": "^4.0.2"
          },
          {
            "name": "slash",
            "version": "^1.0.0"
          },
          {
            "name": "valid-url",
            "version": "^1.0.9"
          }
        ],
        "devDependencies": [
          {
            "name": "cross-env",
            "version": "^5.0.5"
          }
        ],
        "peerDependencies": [
          {
            "name": "gatsby",
            "version": "^1.9.250"
          }
        ],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "4a076ed83e7f91efd5c63a80cdca9b21",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin gatsby-plugin-react-helmet": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby-plugin-react-helmet",
      "id": "Plugin gatsby-plugin-react-helmet",
      "name": "gatsby-plugin-react-helmet",
      "version": "2.0.11",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [],
      "browserAPIs": [],
      "ssrAPIs": [
        "onRenderBody"
      ],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby-plugin-react-helmet",
      "packageJson": {
        "name": "gatsby-plugin-react-helmet",
        "description": "Manage document head data with react-helmet. Provides drop-in server rendering support for Gatsby.",
        "version": "2.0.11",
        "main": "index.js",
        "keywords": [
          "gatsby",
          "gatsby-plugin",
          "favicon",
          "react-helmet",
          "seo",
          "document",
          "head",
          "title",
          "meta",
          "link",
          "script",
          "base",
          "noscript",
          "style"
        ],
        "author": {
          "name": "Kyle Mathews",
          "email": "matthews.kyle@gmail.com"
        },
        "license": "MIT",
        "dependencies": [
          {
            "name": "babel-runtime",
            "version": "^6.26.0"
          }
        ],
        "devDependencies": [
          {
            "name": "babel-cli",
            "version": "^6.26.0"
          },
          {
            "name": "cross-env",
            "version": "^5.0.5"
          }
        ],
        "peerDependencies": [
          {
            "name": "gatsby",
            "version": "^1.0.0"
          },
          {
            "name": "react-helmet",
            "version": ">=5.1.3"
          }
        ],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "9516b0d710ff48572a16478567734989",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin gatsby-transformer-remark": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby-transformer-remark",
      "id": "Plugin gatsby-transformer-remark",
      "name": "gatsby-transformer-remark",
      "version": "1.7.42",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "onCreateNode",
        "setFieldsOnGraphQLNodeType"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net/node_modules/gatsby-transformer-remark",
      "packageJson": {
        "name": "gatsby-transformer-remark",
        "description": "Gatsby transformer plugin for Markdown using the Remark library and ecosystem",
        "version": "1.7.42",
        "keywords": [
          "gatsby",
          "gatsby-plugin",
          "markdown",
          "remark"
        ],
        "author": {
          "name": "Kyle Mathews",
          "email": "mathews.kyle@gmail.com"
        },
        "license": "MIT",
        "dependencies": [
          {
            "name": "babel-runtime",
            "version": "^6.26.0"
          },
          {
            "name": "bluebird",
            "version": "^3.5.0"
          },
          {
            "name": "graphql-type-json",
            "version": "^0.1.4"
          },
          {
            "name": "gray-matter",
            "version": "^3.0.0"
          },
          {
            "name": "hast-util-raw",
            "version": "^2.0.2"
          },
          {
            "name": "hast-util-to-html",
            "version": "^3.0.0"
          },
          {
            "name": "lodash",
            "version": "^4.17.4"
          },
          {
            "name": "mdast-util-to-hast",
            "version": "^2.4.0"
          },
          {
            "name": "mdast-util-toc",
            "version": "^2.0.1"
          },
          {
            "name": "remark",
            "version": "^7.0.1"
          },
          {
            "name": "remark-parse",
            "version": "^4.0.0"
          },
          {
            "name": "remark-retext",
            "version": "^3.1.0"
          },
          {
            "name": "remark-stringify",
            "version": "^4.0.0"
          },
          {
            "name": "retext-english",
            "version": "^3.0.0"
          },
          {
            "name": "sanitize-html",
            "version": "^1.14.1"
          },
          {
            "name": "underscore.string",
            "version": "^3.3.4"
          },
          {
            "name": "unified",
            "version": "^6.1.5"
          },
          {
            "name": "unist-util-remove-position",
            "version": "^1.1.1"
          },
          {
            "name": "unist-util-select",
            "version": "^1.5.0"
          },
          {
            "name": "unist-util-visit",
            "version": "^1.1.1"
          }
        ],
        "devDependencies": [
          {
            "name": "babel-cli",
            "version": "^6.26.0"
          },
          {
            "name": "babel-plugin-transform-object-rest-spread",
            "version": "^6.20.2"
          },
          {
            "name": "cross-env",
            "version": "^5.0.5"
          }
        ],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "0e08094cdee0cb9dc74df23fa1c5883a",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Plugin default-site-plugin": {
      "resolve": "/mnt/c/Users/mbg/Documents/grabeh.net",
      "id": "Plugin default-site-plugin",
      "name": "default-site-plugin",
      "version": "96a4d1c92846d7fd74fe827135cb9293",
      "pluginOptions": {
        "plugins": []
      },
      "nodeAPIs": [
        "createPages"
      ],
      "browserAPIs": [],
      "ssrAPIs": [],
      "pluginFilepath": "/mnt/c/Users/mbg/Documents/grabeh.net",
      "packageJson": {
        "name": "grabeh.net",
        "description": "",
        "version": "1.0.0",
        "main": "index.js",
        "author": "",
        "license": "ISC",
        "dependencies": [
          {
            "name": "classnames",
            "version": "^2.2.5"
          },
          {
            "name": "express",
            "version": "^4.16.3"
          },
          {
            "name": "fs",
            "version": "0.0.1-security"
          },
          {
            "name": "gatsby",
            "version": "^1.9.247"
          },
          {
            "name": "gatsby-link",
            "version": "^1.6.40"
          },
          {
            "name": "gatsby-plugin-react-helmet",
            "version": "^2.0.10"
          },
          {
            "name": "gatsby-remark-prismjs",
            "version": "^2.0.3"
          },
          {
            "name": "gatsby-source-filesystem",
            "version": "^1.5.36"
          },
          {
            "name": "gatsby-transformer-remark",
            "version": "^1.7.42"
          },
          {
            "name": "marked",
            "version": "^0.3.19"
          },
          {
            "name": "prismjs",
            "version": "^1.14.0"
          },
          {
            "name": "react",
            "version": "^16.3.2"
          },
          {
            "name": "react-dom",
            "version": "^16.3.2"
          },
          {
            "name": "react-helmet",
            "version": "^5.2.0"
          },
          {
            "name": "react-highlight",
            "version": "github:briancappello/react-highlight#react-v16-compiled"
          },
          {
            "name": "react-lazyload",
            "version": "^2.3.0"
          },
          {
            "name": "read-file",
            "version": "^0.2.0"
          },
          {
            "name": "rebass",
            "version": "^1.0.7"
          },
          {
            "name": "tachyons-components",
            "version": "^1.0.0-1"
          },
          {
            "name": "to-markdown",
            "version": "^3.1.1"
          }
        ],
        "devDependencies": [
          {
            "name": "prettier",
            "version": "^1.12.0"
          }
        ],
        "peerDependencies": [],
        "optionalDependecies": [],
        "bundledDependecies": []
      },
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "cc68ee9105212e4cf26eb0f3376596d9",
        "type": "SitePlugin",
        "owner": "internal-data-bridge"
      }
    },
    "Site": {
      "siteMetadata": {
        "posts": [
          {
            "title": "A comparison of drafting legal documents vs coding",
            "path": "/A-comparison-of-drafting-legal-documents-vs-coding"
          },
          {
            "path": "/Adventures-with-CouchDB-Nano-and-Pjax",
            "title": "Adventures with CouchDB, Nano and Pjax"
          },
          {
            "path": "/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js",
            "title": "Automated publishing on a VPS using Drafting webhooks and Node.js"
          },
          {
            "path": "/Digital-Ocean-VPS-Nginx-Express-apps",
            "title": "Digital Ocean VPS, Nginx and Express apps"
          },
          {
            "path": "/Image-uploads-and-resizing-with-Transloadit",
            "title": "Image uploads and resizing with Transloadit"
          },
          {
            "path": "/Learnings-from-building-a-basic-Angular.js-app",
            "title": "Learnings from building a basic Angular.js app"
          },
          {
            "path": "/Moving-towards-object-oriented-JavaScript",
            "title": "Moving towards object oriented JavaScript"
          },
          {
            "path": "/Online-terms-better-with-notice",
            "title": "Online terms - better with notice"
          },
          {
            "path": "/Refactoring-from-jQuery-to-Angular.js",
            "title": "Refactoring from jQuery to Angular"
          },
          {
            "path": "/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean",
            "title": "Setting up HTTPS with Express Apps using Nginx and Digital Ocean"
          },
          {
            "path": "Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes",
            "title": "Steps to improve Unity Ubuntu on Chromebook Crouton for developer purposes"
          },
          {
            "path": "/The-journey-from-curious-outsider-to-beginner",
            "title": "The Journey from curious outside to beginner"
          },
          {
            "path": "/The-myth-of-mandatory-trade-mark-enforcement",
            "title": "The myth of mandatory trade mark enforcement"
          }
        ],
        "projects": [
          {
            "projectName": "Attest",
            "description": "Open source contract management platform. Like an excel spreadsheet with less functionality but marginally prettier.",
            "imageUrl": "/attest.png",
            "sourceUrl": "https://github.com/grabbeh/attest",
            "siteUrl": "https://tryattest.com",
            "longDescription": "Contracts are like a flock of sheep. On occasion they can exude a pungent smell. Oh, and they can benefit from someone keeping an eye on them! Many people historically use Excel spreadsheets. However it's 2018 and organisations should be introducing additional points of failure into their organisation. Consequently I decided to create Attest, an open source contract management platform. Oh, and if you want, you can self-host it and build on top of it to your heart's delight because it's licensed under Apache 2.0.",
            "tools": [
              {
                "tool": "Next.js",
                "id": 0
              },
              {
                "tool": "React",
                "id": 1
              },
              {
                "tool": "Node.js",
                "id": 2
              },
              {
                "tool": "MongoDB",
                "id": 3
              },
              {
                "tool": "GraphQL",
                "id": 4
              }
            ],
            "id": 0
          },
          {
            "projectName": "OTTGNaaS",
            "description": "Turn online terms into graphic novels at the flick of a switch (results may vary!)",
            "imageUrl": "/demo.jpg",
            "sourceUrl": "https://github.com/grabbeh/OTTGNaaS",
            "longDescription": "Consumers don't read terms and conditions but some enjoy graphic novels. This project sought to make terms of use palatable to a broader audience by shoehorning them into random graphic novels. The success of the project is largely dependent on legislators obliging companies to make terms of use available in comic form. Lobbying efforts to this end are continuing.",
            "tools": [
              {
                "tool": "Google Cloud Vision API",
                "id": 0
              },
              {
                "tool": "Node.js",
                "id": 1
              },
              {
                "tool": "React",
                "id": 2
              }
            ],
            "id": 1
          },
          {
            "projectName": "Case law emoji bot",
            "description": "Emoji but not as you know it - possibly the future of fostering youth engagement with the law",
            "imageUrl": "/emoji.jpg",
            "sourceUrl": "https://github.com/grabbeh/case-law-emoji-bot",
            "siteUrl": "https://twitter.com/caselawemoji",
            "longDescription": "To large swathes of youth today, the law is a distant mysterious prospect. Emojis on the other hand are almost over-used popping up everywhere. Conveying case law through emojis will lose nothing of the intricate complexities of the law (although it is strongly recommended that you do not rely on emoji summaries in a court of law), but will open up the law to a whole new audience.",
            "tools": [
              {
                "tool": "Twitter API",
                "id": 0
              },
              {
                "tool": "IBM Watson",
                "id": 1
              },
              {
                "tool": "Dango",
                "id": 2
              },
              {
                "tool": "Node.js",
                "id": 3
              }
            ],
            "id": 2
          },
          {
            "projectName": "Fennec",
            "description": "Trade mark portfolio analysis and management",
            "imageUrl": "/fennec.jpg",
            "sourceUrl": "https://github.com/grabbeh/fennec",
            "longDescription": "Managing a global trade mark portfolio is one of the every day tasks that people just have to do. Kind of like cleaning your teeth. This app takes the contents of an Excel spreadsheet, sprinkles them with magic, and spits out a dashboard to help you keep on top of things.",
            "tools": [
              {
                "tool": "Angular",
                "id": 0
              },
              {
                "tool": "Node.js",
                "id": 1
              },
              {
                "tool": "MongoDB",
                "id": 2
              }
            ],
            "id": 3
          },
          {
            "projectName": "Instok",
            "description": "Send reminders to customers when stock is back in",
            "imageUrl": "/instok.jpg",
            "sourceUrl": "https://github.com/grabbeh/instok",
            "longDescription": "When I went to a shop they told me something was out of stock. Neurons fired in my head. The idea for Instok was born! People can buy credits using Stripe, set reminders, and trigger SMSs to delighted customers when stock is back in. We may never know where the name came from.",
            "tools": [
              {
                "tool": "Stripe API",
                "id": 0
              },
              {
                "tool": "Twilio API",
                "id": 1
              },
              {
                "tool": "Angular",
                "id": 2
              },
              {
                "tool": "Node.js",
                "id": 3
              }
            ],
            "id": 4
          },
          {
            "projectName": "Geophoto",
            "description": "Satisfy your virtual wanderlust by looking at photos from places it'd be just dandy to go to",
            "imageUrl": "/geophoto.jpg",
            "sourceUrl": "https://github.com/grabbeh/geophoto",
            "longDescription": "I think it's fair to say that Flickr provides identical functionality, but it gets lost in a swamp of other equally enticing functionality. Geophoto takes the maxim 'Do one thing and do it well' and puts it into overdrive. Find photos of places you'd like to go or definitely wouldn't want to go to but want to confirm your suspicions about just how turgid a place is before accidentally stumbling on a fixer-upper with your name written all over it.",
            "tools": [
              {
                "tool": "Flickr API",
                "id": 0
              },
              {
                "tool": "Angular",
                "id": 1
              },
              {
                "tool": "Node.js",
                "id": 2
              }
            ],
            "id": 5
          },
          {
            "projectName": "Mapopho",
            "description": "Finally, a way to find out which part of the world has the best photos of subject matter X",
            "imageUrl": "/mapopho.jpg",
            "sourceUrl": "https://github.com/grabbeh/mapopho",
            "longDescription": "Flying directly in the face of a Star Trek-esque utopia or perhaps promoting it, this app lets people finally determine the age-old question of which part of the world has the best photos of cats or whatever photo subjects you want (but definitely cats). With that thorny issue resolved people can focus on building bridges not arguing over the relative merits of the cat populations of Honduras and Laos.",
            "tools": [
              {
                "tool": "Flickr API",
                "id": 0
              },
              {
                "tool": "Angular",
                "id": 1
              },
              {
                "tool": "Node.js",
                "id": 2
              }
            ],
            "id": 6
          },
          {
            "projectName": "Routebop",
            "description": "Shares routes with people you do or don't love or feel any kind of emotion for",
            "imageUrl": "/routebop.jpg",
            "sourceUrl": "https://github.com/grabbeh/routebop",
            "longDescription": "Bopping is great but it reaches its peak with it's associated with routes. Routes that take you to places of joy, places of utter mediocrity or places where life may be imperilled (all liability fully disclaimed).",
            "tools": [
              {
                "tool": "jQuery",
                "id": 0
              },
              {
                "tool": "Node.js",
                "id": 1
              },
              {
                "tool": "MongoDB",
                "id": 2
              }
            ],
            "id": 7
          }
        ]
      },
      "pathPrefix": "/public",
      "polyfill": true,
      "buildTime": "2018-06-11T22:00:34.957Z",
      "id": "Site",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "contentDigest": "f5d6aa84e6db2b6522750c9fe2c2b042",
        "type": "Site",
        "owner": "internal-data-bridge"
      }
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown absPath of file",
      "children": [],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "2bb9ec9bc24d292d58a53e19f50896a3",
        "type": "Directory",
        "description": "Directory \"markdown\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "relativePath": "",
      "extension": "",
      "size": 4096,
      "prettySize": "4.1 kB",
      "modifiedTime": "2017-08-25T19:08:59.782Z",
      "accessTime": "2017-08-25T19:08:59.782Z",
      "changeTime": "2017-08-25T19:08:59.782Z",
      "birthTime": "2017-08-25T19:08:59.782Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net",
      "base": "markdown",
      "ext": "",
      "name": "markdown",
      "relativeDirectory": "..",
      "dev": 12,
      "mode": 16895,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 24488322973936156,
      "blocks": 0,
      "atimeMs": 1503688139782.0803,
      "mtimeMs": 1503688139782.0803,
      "ctimeMs": 1503688139782.0803,
      "birthtimeMs": 1503688139782.0803,
      "atime": "2017-08-25T19:08:59.782Z",
      "mtime": "2017-08-25T19:08:59.782Z",
      "ctime": "2017-08-25T19:08:59.782Z",
      "birthtime": "2017-08-25T19:08:59.782Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "a20c4fb19731669c9b32a88052144863",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Adventures-with-CouchDB-Nano-and-Pjax.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md",
      "relativePath": "Adventures-with-CouchDB-Nano-and-Pjax.md",
      "extension": "md",
      "size": 4778,
      "prettySize": "4.78 kB",
      "modifiedTime": "2018-06-10T22:08:49.760Z",
      "accessTime": "2017-08-16T21:38:05.414Z",
      "changeTime": "2018-06-10T22:08:49.760Z",
      "birthTime": "2018-06-10T22:08:49.760Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Adventures-with-CouchDB-Nano-and-Pjax.md",
      "ext": ".md",
      "name": "Adventures-with-CouchDB-Nano-and-Pjax",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 14073748835644576,
      "blocks": 16,
      "atimeMs": 1502919485413.9172,
      "mtimeMs": 1528668529760.0647,
      "ctimeMs": 1528668529760.0647,
      "birthtimeMs": 1528668529760.0647,
      "atime": "2017-08-16T21:38:05.414Z",
      "mtime": "2018-06-10T22:08:49.760Z",
      "ctime": "2018-06-10T22:08:49.760Z",
      "birthtime": "2018-06-10T22:08:49.760Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "49dd92e832b5fa0417977af180dd9ea5",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/A-comparison-of-drafting-legal-documents-vs-coding.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md",
      "relativePath": "A-comparison-of-drafting-legal-documents-vs-coding.md",
      "extension": "md",
      "size": 7442,
      "prettySize": "7.44 kB",
      "modifiedTime": "2018-06-10T21:03:18.739Z",
      "accessTime": "2017-08-16T21:38:05.320Z",
      "changeTime": "2018-06-10T21:03:18.739Z",
      "birthTime": "2018-06-10T21:03:18.739Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "A-comparison-of-drafting-legal-documents-vs-coding.md",
      "ext": ".md",
      "name": "A-comparison-of-drafting-legal-documents-vs-coding",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 35465847065652892,
      "blocks": 16,
      "atimeMs": 1502919485320,
      "mtimeMs": 1528664598739.1765,
      "ctimeMs": 1528664598739.1765,
      "birthtimeMs": 1528664598739.1765,
      "atime": "2017-08-16T21:38:05.320Z",
      "mtime": "2018-06-10T21:03:18.739Z",
      "ctime": "2018-06-10T21:03:18.739Z",
      "birthtime": "2018-06-10T21:03:18.739Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "2003dd763db4bf6f36de3c59b03aed95",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Digital-Ocean-VPS-Nginx-Express-apps.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md",
      "relativePath": "Digital-Ocean-VPS-Nginx-Express-apps.md",
      "extension": "md",
      "size": 6882,
      "prettySize": "6.88 kB",
      "modifiedTime": "2018-06-10T23:33:25.473Z",
      "accessTime": "2017-08-16T21:38:05.499Z",
      "changeTime": "2018-06-10T23:33:25.473Z",
      "birthTime": "2018-06-10T23:33:25.473Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Digital-Ocean-VPS-Nginx-Express-apps.md",
      "ext": ".md",
      "name": "Digital-Ocean-VPS-Nginx-Express-apps",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 7036874417880069,
      "blocks": 16,
      "atimeMs": 1502919485499.1184,
      "mtimeMs": 1528673605473.1753,
      "ctimeMs": 1528673605473.1753,
      "birthtimeMs": 1528673605473.1753,
      "atime": "2017-08-16T21:38:05.499Z",
      "mtime": "2018-06-10T23:33:25.473Z",
      "ctime": "2018-06-10T23:33:25.473Z",
      "birthtime": "2018-06-10T23:33:25.473Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "273eec8237944b07fa08720b47ed1a33",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Learnings-from-building-a-basic-Angular.js-app.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md",
      "relativePath": "Learnings-from-building-a-basic-Angular.js-app.md",
      "extension": "md",
      "size": 7465,
      "prettySize": "7.46 kB",
      "modifiedTime": "2018-06-10T20:16:45.656Z",
      "accessTime": "2017-08-16T21:38:05.576Z",
      "changeTime": "2018-06-10T20:16:45.656Z",
      "birthTime": "2018-06-10T20:16:45.656Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Learnings-from-building-a-basic-Angular.js-app.md",
      "ext": ".md",
      "name": "Learnings-from-building-a-basic-Angular.js-app",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 2533274790573234,
      "blocks": 16,
      "atimeMs": 1502919485576.3235,
      "mtimeMs": 1528661805655.7917,
      "ctimeMs": 1528661805655.7917,
      "birthtimeMs": 1528661805655.7917,
      "atime": "2017-08-16T21:38:05.576Z",
      "mtime": "2018-06-10T20:16:45.656Z",
      "ctime": "2018-06-10T20:16:45.656Z",
      "birthtime": "2018-06-10T20:16:45.656Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "a6d0901ce09e29cef0de3f91c3b00aa9",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Moving-towards-object-oriented-JavaScript.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md",
      "relativePath": "Moving-towards-object-oriented-JavaScript.md",
      "extension": "md",
      "size": 6824,
      "prettySize": "6.82 kB",
      "modifiedTime": "2018-06-10T23:23:37.939Z",
      "accessTime": "2017-08-16T21:38:05.609Z",
      "changeTime": "2018-06-10T23:23:37.939Z",
      "birthTime": "2018-06-10T23:23:37.939Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Moving-towards-object-oriented-JavaScript.md",
      "ext": ".md",
      "name": "Moving-towards-object-oriented-JavaScript",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 3096224743999647,
      "blocks": 16,
      "atimeMs": 1502919485609.4478,
      "mtimeMs": 1528673017939.448,
      "ctimeMs": 1528673017939.448,
      "birthtimeMs": 1528673017939.448,
      "atime": "2017-08-16T21:38:05.609Z",
      "mtime": "2018-06-10T23:23:37.939Z",
      "ctime": "2018-06-10T23:23:37.939Z",
      "birthtime": "2018-06-10T23:23:37.939Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "bc567ea0c93afd95fd5327bd1650e834",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Online-terms-better-with-notice.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md",
      "relativePath": "Online-terms-better-with-notice.md",
      "extension": "md",
      "size": 4178,
      "prettySize": "4.18 kB",
      "modifiedTime": "2018-06-10T20:12:02.958Z",
      "accessTime": "2017-08-16T21:38:05.627Z",
      "changeTime": "2018-06-10T20:12:02.958Z",
      "birthTime": "2018-06-10T20:12:02.958Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Online-terms-better-with-notice.md",
      "ext": ".md",
      "name": "Online-terms-better-with-notice",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 3096224743999667,
      "blocks": 16,
      "atimeMs": 1502919485627.4597,
      "mtimeMs": 1528661522958.2986,
      "ctimeMs": 1528661522958.2986,
      "birthtimeMs": 1528661522958.2986,
      "atime": "2017-08-16T21:38:05.627Z",
      "mtime": "2018-06-10T20:12:02.958Z",
      "ctime": "2018-06-10T20:12:02.958Z",
      "birthtime": "2018-06-10T20:12:02.958Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "07e1b6923524070d79822265f171566b",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Refactoring-from-jQuery-to-Angular.js.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md",
      "relativePath": "Refactoring-from-jQuery-to-Angular.js.md",
      "extension": "md",
      "size": 7557,
      "prettySize": "7.56 kB",
      "modifiedTime": "2018-06-10T22:01:30.760Z",
      "accessTime": "2017-08-16T21:38:05.671Z",
      "changeTime": "2018-06-10T22:01:30.760Z",
      "birthTime": "2018-06-10T22:01:30.760Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Refactoring-from-jQuery-to-Angular.js.md",
      "ext": ".md",
      "name": "Refactoring-from-jQuery-to-Angular.js",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 2533274790578440,
      "blocks": 16,
      "atimeMs": 1502919485670.5752,
      "mtimeMs": 1528668090760.473,
      "ctimeMs": 1528668090760.473,
      "birthtimeMs": 1528668090760.473,
      "atime": "2017-08-16T21:38:05.671Z",
      "mtime": "2018-06-10T22:01:30.760Z",
      "ctime": "2018-06-10T22:01:30.760Z",
      "birthtime": "2018-06-10T22:01:30.760Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "9080f73e9b4065779a3a0e1d6c8f804a",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md",
      "relativePath": "Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md",
      "extension": "md",
      "size": 3967,
      "prettySize": "3.97 kB",
      "modifiedTime": "2018-06-10T20:12:16.320Z",
      "accessTime": "2017-08-16T21:38:05.692Z",
      "changeTime": "2018-06-10T20:12:16.320Z",
      "birthTime": "2018-06-10T20:12:16.320Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md",
      "ext": ".md",
      "name": "Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 2814749767289126,
      "blocks": 8,
      "atimeMs": 1502919485691.663,
      "mtimeMs": 1528661536319.9956,
      "ctimeMs": 1528661536319.9956,
      "birthtimeMs": 1528661536319.9956,
      "atime": "2017-08-16T21:38:05.692Z",
      "mtime": "2018-06-10T20:12:16.320Z",
      "ctime": "2018-06-10T20:12:16.320Z",
      "birthtime": "2018-06-10T20:12:16.320Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "ba764306e8e4b233126cab271a900a15",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md",
      "relativePath": "Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md",
      "extension": "md",
      "size": 3050,
      "prettySize": "3.05 kB",
      "modifiedTime": "2018-06-10T21:27:46.102Z",
      "accessTime": "2017-08-16T21:38:05.714Z",
      "changeTime": "2018-06-10T21:27:46.102Z",
      "birthTime": "2018-06-10T21:27:46.102Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md",
      "ext": ".md",
      "name": "Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 3377699720710470,
      "blocks": 8,
      "atimeMs": 1502919485714,
      "mtimeMs": 1528666066102.0327,
      "ctimeMs": 1528666066102.0327,
      "birthtimeMs": 1528666066102.0327,
      "atime": "2017-08-16T21:38:05.714Z",
      "mtime": "2018-06-10T21:27:46.102Z",
      "ctime": "2018-06-10T21:27:46.102Z",
      "birthtime": "2018-06-10T21:27:46.102Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "a3f49f856c1fee685b6701b48d07145b",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/The-journey-from-curious-outsider-to-beginner.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md",
      "relativePath": "The-journey-from-curious-outsider-to-beginner.md",
      "extension": "md",
      "size": 6665,
      "prettySize": "6.67 kB",
      "modifiedTime": "2018-06-10T20:10:37.307Z",
      "accessTime": "2017-08-16T21:38:05.745Z",
      "changeTime": "2018-06-10T20:10:37.307Z",
      "birthTime": "2018-06-10T20:10:37.307Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "The-journey-from-curious-outsider-to-beginner.md",
      "ext": ".md",
      "name": "The-journey-from-curious-outsider-to-beginner",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 2251799813867885,
      "blocks": 16,
      "atimeMs": 1502919485744.9998,
      "mtimeMs": 1528661437307.288,
      "ctimeMs": 1528661437307.288,
      "birthtimeMs": 1528661437307.288,
      "atime": "2017-08-16T21:38:05.745Z",
      "mtime": "2018-06-10T20:10:37.307Z",
      "ctime": "2018-06-10T20:10:37.307Z",
      "birthtime": "2018-06-10T20:10:37.307Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "e10800e00d0a9e7415e94c9c921fe5ba",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md",
      "relativePath": "Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md",
      "extension": "md",
      "size": 3756,
      "prettySize": "3.76 kB",
      "modifiedTime": "2018-06-10T20:16:26.608Z",
      "accessTime": "2017-08-16T21:38:05.451Z",
      "changeTime": "2018-06-10T20:16:26.608Z",
      "birthTime": "2018-06-10T20:16:26.608Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md",
      "ext": ".md",
      "name": "Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 25614222880781744,
      "blocks": 8,
      "atimeMs": 1502919485450.99,
      "mtimeMs": 1528661786608.0625,
      "ctimeMs": 1528661786608.0625,
      "birthtimeMs": 1528661786608.0625,
      "atime": "2017-08-16T21:38:05.451Z",
      "mtime": "2018-06-10T20:16:26.608Z",
      "ctime": "2018-06-10T20:16:26.608Z",
      "birthtime": "2018-06-10T20:16:26.608Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "0eb3e14ef0f1555578dd9604f8598294",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/Image-uploads-and-resizing-with-Transloadit.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md",
      "relativePath": "Image-uploads-and-resizing-with-Transloadit.md",
      "extension": "md",
      "size": 3828,
      "prettySize": "3.83 kB",
      "modifiedTime": "2018-06-10T20:13:54.939Z",
      "accessTime": "2017-08-16T21:38:05.549Z",
      "changeTime": "2018-06-10T20:13:54.939Z",
      "birthTime": "2018-06-10T20:13:54.939Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "Image-uploads-and-resizing-with-Transloadit.md",
      "ext": ".md",
      "name": "Image-uploads-and-resizing-with-Transloadit",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 5348024557625943,
      "blocks": 8,
      "atimeMs": 1502919485549.2512,
      "mtimeMs": 1528661634939.2803,
      "ctimeMs": 1528661634939.2803,
      "birthtimeMs": 1528661634939.2803,
      "atime": "2017-08-16T21:38:05.549Z",
      "mtime": "2018-06-10T20:13:54.939Z",
      "ctime": "2018-06-10T20:13:54.939Z",
      "birthtime": "2018-06-10T20:13:54.939Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file",
      "children": [
        "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file >>> MarkdownRemark"
      ],
      "parent": "___SOURCE___",
      "internal": {
        "contentDigest": "f0b0a4d9d18e2852cb1fb1b8b76ae4cf",
        "mediaType": "text/markdown",
        "type": "File",
        "description": "File \"markdown/The-myth-of-mandatory-trade-mark-enforcement.md\"",
        "owner": "gatsby-source-filesystem"
      },
      "sourceInstanceName": "markdown-pages",
      "absolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md",
      "relativePath": "The-myth-of-mandatory-trade-mark-enforcement.md",
      "extension": "md",
      "size": 6276,
      "prettySize": "6.28 kB",
      "modifiedTime": "2018-06-10T21:03:43.462Z",
      "accessTime": "2017-08-16T21:38:05.775Z",
      "changeTime": "2018-06-10T21:03:43.462Z",
      "birthTime": "2018-06-10T21:03:43.462Z",
      "root": "/",
      "dir": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown",
      "base": "The-myth-of-mandatory-trade-mark-enforcement.md",
      "ext": ".md",
      "name": "The-myth-of-mandatory-trade-mark-enforcement",
      "relativeDirectory": "",
      "dev": 12,
      "mode": 33279,
      "nlink": 1,
      "uid": 1000,
      "gid": 1000,
      "rdev": 0,
      "blksize": 4096,
      "ino": 2533274790578546,
      "blocks": 16,
      "atimeMs": 1502919485774.8516,
      "mtimeMs": 1528664623461.8997,
      "ctimeMs": 1528664623461.8997,
      "birthtimeMs": 1528664623461.8997,
      "atime": "2017-08-16T21:38:05.775Z",
      "mtime": "2018-06-10T21:03:43.462Z",
      "ctime": "2018-06-10T21:03:43.462Z",
      "birthtime": "2018-06-10T21:03:43.462Z"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file",
      "internal": {
        "content": "---\npath: '/Adventures-with-CouchDB-Nano-and-Pjax'\ntitle: 'Adventures with CouchDB, Nano and Pjax'\n---\n\nIt seemed fitting to write the first blog on here about the process of creating the blog itself, so whilst I hope to write on a broader range of topics on the above in future, what follows below is some comment on the tools used to build this blog.\n\n**CouchDB and Nano**\n\nWhilst the main site utilises MongoDB for persistence, when I was originally looking at options for persistence, [CouchDB](http://couchdb.apache.org/) was of interest, so although I ending up opting for MongoDB, CouchDB always stuck with me. So as it was, when I decided it would be a good idea to get some thoughts down, I thought it would be a nice little project to put together a blog using CouchDB for persistence.\n\nWhen looking at how to interface with CouchDB I considered a few options. Initially, I thought it would be nice to make HTTP requests directly to a CouchDB instance. I looked at [browser-request](https://github.com/iriscouch/browser-request), a library from the guys at [IrisCouch](http://www.iriscouch.com) (who coincidentally are the provider of the CouchDB instance used by this blog (thanks!)).\n\nHaving played around with the browser variant, I ended up realising that it may be less cluttered to separate out concerns and leave the client-side purely for rendering the finished product.\n\nHaving decided to use Node together with CouchDB, it wasn't long before I stumbled on [Nano](http://github.com/dscape/nano) by Nuno Job. Nano is a basic wrapper which simplifies greatly interactions with your CouchDB instance. There were a few points with CouchDB and Nano that were and in some cases still are stumbling for me as per the below.\n\n**Creating a database**\n\nNano exposes a .use method to specify which database you are going to use. This assumes it has previously been created, so the first step would be to create the database. However, the issue for me is that once created, you don’t want to then subsequently create a further database on each occasion. I need to therefore figure out to perhaps only create a database if it doesn’t already exist.\n\n**CouchDB views**\n\nComing from MongoDB/Mongoose, it took me a while to realise that CouchDB uses the concept of views to process and display data from the database. A view can be as simple as the below:\n\n    function(doc) {\n      emit(doc._id, doc);\n    }\n\nThis will simply map over the specified database and output an object for each row in the database, with that object containing the stored values. In addition to this basic functionality, you can of course do a much greater range of operations including reducing queries. More information on views can be found in this [great answer](http://stackoverflow.com/a/7112722/1242579) on Stack Overflow. It is worth noting that the view must be stored directly in your CouchDB instance using the Futon manager.\n\n**Updating a document**\n\nThe concept of updating a document is from what I can tell frowned up on in CouchDB, rather than updating a document, you are essentially changing the pointer in your database so it point to a revised document. As a result, you have to supply the version of the document you wish to update. At the same time, I haven’t quite worked out if it is possible to only update certain values in an entry so at present, in addition to any amended values, I also supply the unchanged values. This to me is rather unwieldy.\n\n**Pjax**\n\nThe site also uses [Pjax](http://pjax.heroku.com). This tool grabs html content from the server via AJAX but at the same time uses html5 pushstate to alter the url accordingly. As the details at the link states this gives the impression of a speeded up site as the whole page isn’t being reloaded. One issue for me with this tool is that when I edit a page and import content from the server, it doesn’t render correctly. As a result, I have disabled the pjax functionality for the edit page.\n\nAnother issue I haven't worked out is how to automatically enable pjax. Although I'm sure it's trivial, in the demo it is dealt via a checkbox (as this enables you to determine performance with and without pjax enabled).\n\nTo get Jquery-Pjax working with Express 3 I revised the demo [here](https://github.com/dakatsuka/express-pjax) to use express-partials, which allows the use of layouts with Express 3\\. This is because pjax works by injecting the html from the server into a specified section of the layout.\n\n**Concluding thoughts**\n\nThe code for the small blog I have created is available [on Github](http://www.github.com/grabbeh/nanoblog). It is a work in progress and I hope to try to resolve some of the unresolved issues above (or some kindly person will stumble on this blog and enlighten me!).\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "c49bcc011b1fb6797fb636cc25cc3ad7",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Adventures with CouchDB, Nano and Pjax",
        "path": "/Adventures-with-CouchDB-Nano-and-Pjax",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nIt seemed fitting to write the first blog on here about the process of creating the blog itself, so whilst I hope to write on a broader range of topics on the above in future, what follows below is some comment on the tools used to build this blog.\n\n**CouchDB and Nano**\n\nWhilst the main site utilises MongoDB for persistence, when I was originally looking at options for persistence, [CouchDB](http://couchdb.apache.org/) was of interest, so although I ending up opting for MongoDB, CouchDB always stuck with me. So as it was, when I decided it would be a good idea to get some thoughts down, I thought it would be a nice little project to put together a blog using CouchDB for persistence.\n\nWhen looking at how to interface with CouchDB I considered a few options. Initially, I thought it would be nice to make HTTP requests directly to a CouchDB instance. I looked at [browser-request](https://github.com/iriscouch/browser-request), a library from the guys at [IrisCouch](http://www.iriscouch.com) (who coincidentally are the provider of the CouchDB instance used by this blog (thanks!)).\n\nHaving played around with the browser variant, I ended up realising that it may be less cluttered to separate out concerns and leave the client-side purely for rendering the finished product.\n\nHaving decided to use Node together with CouchDB, it wasn't long before I stumbled on [Nano](http://github.com/dscape/nano) by Nuno Job. Nano is a basic wrapper which simplifies greatly interactions with your CouchDB instance. There were a few points with CouchDB and Nano that were and in some cases still are stumbling for me as per the below.\n\n**Creating a database**\n\nNano exposes a .use method to specify which database you are going to use. This assumes it has previously been created, so the first step would be to create the database. However, the issue for me is that once created, you don’t want to then subsequently create a further database on each occasion. I need to therefore figure out to perhaps only create a database if it doesn’t already exist.\n\n**CouchDB views**\n\nComing from MongoDB/Mongoose, it took me a while to realise that CouchDB uses the concept of views to process and display data from the database. A view can be as simple as the below:\n\n    function(doc) {\n      emit(doc._id, doc);\n    }\n\nThis will simply map over the specified database and output an object for each row in the database, with that object containing the stored values. In addition to this basic functionality, you can of course do a much greater range of operations including reducing queries. More information on views can be found in this [great answer](http://stackoverflow.com/a/7112722/1242579) on Stack Overflow. It is worth noting that the view must be stored directly in your CouchDB instance using the Futon manager.\n\n**Updating a document**\n\nThe concept of updating a document is from what I can tell frowned up on in CouchDB, rather than updating a document, you are essentially changing the pointer in your database so it point to a revised document. As a result, you have to supply the version of the document you wish to update. At the same time, I haven’t quite worked out if it is possible to only update certain values in an entry so at present, in addition to any amended values, I also supply the unchanged values. This to me is rather unwieldy.\n\n**Pjax**\n\nThe site also uses [Pjax](http://pjax.heroku.com). This tool grabs html content from the server via AJAX but at the same time uses html5 pushstate to alter the url accordingly. As the details at the link states this gives the impression of a speeded up site as the whole page isn’t being reloaded. One issue for me with this tool is that when I edit a page and import content from the server, it doesn’t render correctly. As a result, I have disabled the pjax functionality for the edit page.\n\nAnother issue I haven't worked out is how to automatically enable pjax. Although I'm sure it's trivial, in the demo it is dealt via a checkbox (as this enables you to determine performance with and without pjax enabled).\n\nTo get Jquery-Pjax working with Express 3 I revised the demo [here](https://github.com/dakatsuka/express-pjax) to use express-partials, which allows the use of layouts with Express 3\\. This is because pjax works by injecting the html from the server into a specified section of the layout.\n\n**Concluding thoughts**\n\nThe code for the small blog I have created is available [on Github](http://www.github.com/grabbeh/nanoblog). It is a work in progress and I hope to try to resolve some of the unresolved issues above (or some kindly person will stumble on this blog and enlighten me!).\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file",
      "internal": {
        "content": "---\npath: '/Online-terms-better-with-notice'\ntitle: 'Online terms - better with notice'\n---\n\nIn some countries in the world, laws are in place to help protect the consumer against the imposition of unfair contract terms.\n\nThe rationale behind such laws is ensure that a company cannot take advantage of the fact that a customer is not always in a position to understand standard terms placed in front of them, and is also in a relatively weak bargaining position to make any changes to terms.\n\nAt the same time, especially in e-commerce terms, it's important to not present any major hurdles to a consumer's usage of e-commerce. For example, not providing protections would mean that consumers would be more likely (ok, only a little more likely) to wade through terms to make sure there wasn't anything unduly onerous.\n\nConsumer protection regulations mean that a customer can be relatively assured that regardless of the terms they sign up to (which are generally unread) because of consumer protection regulations, the terms will either a) be reasonable in the first instance or b) if they do contain unreasonable terms, they will be struck out if a company ever sought to enforce them.\n\nAlthough the above protections are in most cases likely to mean that the vast blocks of text that often form online terms will not contain anything nasty, there are steps that a website provider can take to improve their chances of being able to rely on its terms.\n\nFor example it's important to use plain language in your terms and also to highlight any particularly onerous terms (even if their own right they may be entirely reasonable).\n\nOne of the UK's most famous judges, Lord Denning in the case of [J Spurling Ltd v Bradshaw](http://en.wikipedia.org/wiki/J_Spurling_Ltd_v_Bradshaw) [1956] EWCA Civ 3 offered a particularly pertinent quote back in 1956 commenting that:\n\n<div class=\"quote\">\"I quite agree that the more unreasonable a clause is, the greater the notice which must be given of it. Some clauses which I have seen would need to be printed in red ink on the face of the document with a red hand pointing to it before the notice could be held to be sufficient.\"</div>\n\nWith online terms it could be a good idea to highlight to a customer where a particularly onerous term is proposed to be introduced.\n\nWith this in mind, I thought it would be interesting to try to use some code to introduce this into some generic terms (Lorem Ipsum in this case). Using [Skrollr.js](https://github.com/Prinzhorn/skrollr), I created some functionality so as a user scrolls down the page, highlighted blocks move into view alerting them to particularly onerous terms.\n\nThe example can be found [here](http://legal-terms-example.grabeh.net). Scrolling down should result in the warning notices appearing (although only on desktop at the moment).\n\nAt the moment, a two column approach is taken and with Skrollr you can use relative positioning to adjust the styling of an element dependent on its position relative to the top and bottom of the viewport. Here's an example for one of the boxes.\n\n    <div class=\"imp-text\" \n    data-25-top-top=\"opacity: 1; background: rgb(255,247,165); left: 0px;\" \n    data-25-top-bottom=\"opacity: 0; background: rgb(255,255,255); left: 200px;\" \n    data--25-bottom-top=\"opacity: 0; left: 200px; background: rgb(255,255,255);\" \n    data--25-bottom-bottom=\"opacity: 1; left: 0px; background: rgb(255,247,165);\">\n    Kidney due within 30 days of signature</div>\n\nIn the example by using 'top-top' (top of viewport and top of element) and 'top-bottom' (still top of viewport and bottom of element) and introducing changes in style between the two, scrolling between will smoothly transition between the two styles.\n\nWhilst some of the term used on the page may not quite cut the mustard in terms of being reasonable, the important point to take away is that by highlighting the terms, you're more likely to have provided sufficient notice to the user.\n\nIn part, consumer law assumes a user may not read the terms, but if a company takes appropriate steps to notify its users about onerous terms, it is more likely they'll be able to rely on them in future.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "027925bddd41afc8bc0842a9e5e4876e",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Online terms - better with notice",
        "path": "/Online-terms-better-with-notice",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nIn some countries in the world, laws are in place to help protect the consumer against the imposition of unfair contract terms.\n\nThe rationale behind such laws is ensure that a company cannot take advantage of the fact that a customer is not always in a position to understand standard terms placed in front of them, and is also in a relatively weak bargaining position to make any changes to terms.\n\nAt the same time, especially in e-commerce terms, it's important to not present any major hurdles to a consumer's usage of e-commerce. For example, not providing protections would mean that consumers would be more likely (ok, only a little more likely) to wade through terms to make sure there wasn't anything unduly onerous.\n\nConsumer protection regulations mean that a customer can be relatively assured that regardless of the terms they sign up to (which are generally unread) because of consumer protection regulations, the terms will either a) be reasonable in the first instance or b) if they do contain unreasonable terms, they will be struck out if a company ever sought to enforce them.\n\nAlthough the above protections are in most cases likely to mean that the vast blocks of text that often form online terms will not contain anything nasty, there are steps that a website provider can take to improve their chances of being able to rely on its terms.\n\nFor example it's important to use plain language in your terms and also to highlight any particularly onerous terms (even if their own right they may be entirely reasonable).\n\nOne of the UK's most famous judges, Lord Denning in the case of [J Spurling Ltd v Bradshaw](http://en.wikipedia.org/wiki/J_Spurling_Ltd_v_Bradshaw) [1956] EWCA Civ 3 offered a particularly pertinent quote back in 1956 commenting that:\n\n<div class=\"quote\">\"I quite agree that the more unreasonable a clause is, the greater the notice which must be given of it. Some clauses which I have seen would need to be printed in red ink on the face of the document with a red hand pointing to it before the notice could be held to be sufficient.\"</div>\n\nWith online terms it could be a good idea to highlight to a customer where a particularly onerous term is proposed to be introduced.\n\nWith this in mind, I thought it would be interesting to try to use some code to introduce this into some generic terms (Lorem Ipsum in this case). Using [Skrollr.js](https://github.com/Prinzhorn/skrollr), I created some functionality so as a user scrolls down the page, highlighted blocks move into view alerting them to particularly onerous terms.\n\nThe example can be found [here](http://legal-terms-example.grabeh.net). Scrolling down should result in the warning notices appearing (although only on desktop at the moment).\n\nAt the moment, a two column approach is taken and with Skrollr you can use relative positioning to adjust the styling of an element dependent on its position relative to the top and bottom of the viewport. Here's an example for one of the boxes.\n\n    <div class=\"imp-text\" \n    data-25-top-top=\"opacity: 1; background: rgb(255,247,165); left: 0px;\" \n    data-25-top-bottom=\"opacity: 0; background: rgb(255,255,255); left: 200px;\" \n    data--25-bottom-top=\"opacity: 0; left: 200px; background: rgb(255,255,255);\" \n    data--25-bottom-bottom=\"opacity: 1; left: 0px; background: rgb(255,247,165);\">\n    Kidney due within 30 days of signature</div>\n\nIn the example by using 'top-top' (top of viewport and top of element) and 'top-bottom' (still top of viewport and bottom of element) and introducing changes in style between the two, scrolling between will smoothly transition between the two styles.\n\nWhilst some of the term used on the page may not quite cut the mustard in terms of being reasonable, the important point to take away is that by highlighting the terms, you're more likely to have provided sufficient notice to the user.\n\nIn part, consumer law assumes a user may not read the terms, but if a company takes appropriate steps to notify its users about onerous terms, it is more likely they'll be able to rely on them in future.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file",
      "internal": {
        "content": "---\ntitle: 'A comparison of drafting legal documents vs coding'\npath: '/A-comparison-of-drafting-legal-documents-vs-coding'\n---\n\nHaving done a lot of legal drafting in my time and a little [coding](https://github.com/grabbeh) also, I started to notice a few similarities between the two processes which I thought I'd write about. I also talk about one way in which the two processes diverge.\n\n**Avoiding repetition and keeping things DRY**\n\nWhen drafting legal documents, I'll sometimes find myself repeating a specific phrase or collection of words. To remove this repetition, you can create a defined term and then use the same defined term throughout the agreement.\n\nFor example \"Confidential Information\" can be defined and then re-used throughout the agreement (making it as broad or as narrow as you might like, subject to enforceability).\n\nThis could be broadly analogous to using functions to collect together a specific area of functionality which can then be re-used without repeating the original code.\n\n**Separation of concerns**\n\nWhen you're working in an organisation with agreements that will be re-used frequently and by non-lawyers, it's good to separate out firstly as much as possible content that will need to change each time the document is used, and secondly content that is standard and is therefore unlikely in the first instance to change. Although sending it over to the other side's lawyers is a different matter.\n\nThis can be done by moving changeable terms (price, delivery schedule, licence period etc) from the main body of the agreement into a schedule. This way when it comes to be re-used the user will only need to update the schedule and will not have to get involved with the main body of the agreement. Overall this hopefully means that the time to get a contract out to the other side is greatly reduced, or at least that's the plan.\n\nThis has parallels with avoiding the use of CSS and Javascript inline in HTML. If for example you're allowing a user to customise a simple layout, then there isn't necessarily a need to have the user interact with the HTML itself as, depending on the circumstances of course.\n\nIf everything is inline and a jumble of CSS, JS and HTML I would argue this increases the chances of a particular style update being missed (as is the case with an agreement, where the risk of missing an update to a changeable term is increased if everything is within the body of the agreement).\n\n**Straining the analogy**\n\nYou could go as far as to say that the main body of an agreement is the view, the schedule with variables is the model, and the definitions section is the controller/router, providing the glue between the model and the view, defining how the terms in the schedule (price, payment terms, work period) are used in the view.\n\n![](/legalmvc.png \"It's MVC, but not as we know it, Jim\")\n\n**User feedback**\n\nA little trite, but both from a legal and a coding perspective, it's really important to have the results of your efforts reviewed by those who will be actually using the end result. Within my organisation, after I've drafted the document it will go out to the people who asked me to draft it in the first place for comments.\n\nAs a side-note, whether or not they'll give it a thorough read-through depends a) on the person's dedication to ensuring the terms of the proposed work are accurately reflected in the agreement and b) their trust in the abilities of the legal department!\n\nIn both cases you'll quickly find out what the important parts are and where improvements are desired, even if perhaps the full extent of the work isn't thoroughly assessed. If you're working for a services-based organisation, the expenses clause is generally the most important aspect of the agreement.\n\n**Modularity**\n\nMost agreements will have a set of standard clauses which you will find in most agreements, like choice of law, limitation of liability, assignment, waiver, and variation. Being able to slot these in and not have to worry about drafting new clauses each time takes time out the drafting process. This leaves time to focus on the elements unique to the agreement.\n\nIn the same way, when coding web applications, you will most likely have standard pieces of functionality like user authentication and file uploads, or frameworks like [Foundation](http://foundation.zurb.com/), [Bootstrap](http://getbootstrap.com/)and [Pure.CSS](http://purecss.io/) for the appearance of an app. Mozilla's Brick and Google's Polymer also open up the possibility of packaging up discrete elements of functionality.\n\n**But where do they differ?**\n\nIt's fair to say there's one pretty glaring way in which the two processes differ. If I want to draft a document I'm much more restricted in the way I can go out and grab existing examples that are free to use.\n\nThis is in stark contract to the many open source options that are available to help a person to quickly incorporate functionality into an app (at least in my experience in using [Node.js](http://nodejs.org) and [Express](http://expressjs.com)).\n\nSome folks including [Legal Zoom](http://www.legalzoom.com) and [Docracy](http://www.docracy.com) are taking steps to simplify the process for many users of legal services (in the case of the former and the latter) and to allow lawyers to provide and comment on agreements (in the case of the latter).\n\nHowever at present there isn't a widely-used service like Github where to extend the analogy and in the context of open source code, lawyers from different firms collaborate on improving documents used by all or used by many different people<sup id=\"fnref1\">[1](#fn1)</sup> (perhaps an overly broad definition) or lawyers might develop a set of wording internally and decide to release it for general consumption.\n\nWhether this will change in the future remains to be seen however, there are good reasons for this reduced participation:\n\n*   unlike software companies, law firms are less likely to gain goodwill as a result of making available clauses\n*   even standard clauses can need to be changed depending on the specific circumstances of a deal, reducing the benefit of open sourcing them in the first place\n*   confidentiality issues are more likely to be an issue\n*   perhaps most importantly, law firms act for clients who may take umbrage at releasing work (even if completely anonymised) as a third party could still benefit from the work, particularly bespoke drafting\n\nI'm not saying that many of these reasons cannot be overcome but at present the above barriers are sufficient to prevent wider participation by lawyers in open sourcing of legal documentation<sup id=\"fnref2\">[2](#fn2)</sup>.\n\nAs for the future, it will be interesting to see whether start-ups operating in the legal sector will be able to exert sufficient influence or make it attractive enough for large volumes of lawyers to start doing this.\n\n\n* * *\n\n1.  There are movements in certain niche areas where lawyers do collaborate to improve documents to a standard like [ISDA](http://www2.isda.org/) (for financial swaps and derivatives) and the [JCT](http://www.jctltd.co.uk/) for construction contracts but this is still a relatively closed system and is the exception rather than the rule. [↩](#fnref1)\n\n2.  One counter-example is the [Innovators Patent Agreement](https://github.com/twitter/innovators-patent-agreement/blob/master/innovators-patent-agreement.md).  [↩](#fnref2)\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "01f04681e5fedffaf3eb7568ff13d0d1",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "A comparison of drafting legal documents vs coding",
        "path": "/A-comparison-of-drafting-legal-documents-vs-coding",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nHaving done a lot of legal drafting in my time and a little [coding](https://github.com/grabbeh) also, I started to notice a few similarities between the two processes which I thought I'd write about. I also talk about one way in which the two processes diverge.\n\n**Avoiding repetition and keeping things DRY**\n\nWhen drafting legal documents, I'll sometimes find myself repeating a specific phrase or collection of words. To remove this repetition, you can create a defined term and then use the same defined term throughout the agreement.\n\nFor example \"Confidential Information\" can be defined and then re-used throughout the agreement (making it as broad or as narrow as you might like, subject to enforceability).\n\nThis could be broadly analogous to using functions to collect together a specific area of functionality which can then be re-used without repeating the original code.\n\n**Separation of concerns**\n\nWhen you're working in an organisation with agreements that will be re-used frequently and by non-lawyers, it's good to separate out firstly as much as possible content that will need to change each time the document is used, and secondly content that is standard and is therefore unlikely in the first instance to change. Although sending it over to the other side's lawyers is a different matter.\n\nThis can be done by moving changeable terms (price, delivery schedule, licence period etc) from the main body of the agreement into a schedule. This way when it comes to be re-used the user will only need to update the schedule and will not have to get involved with the main body of the agreement. Overall this hopefully means that the time to get a contract out to the other side is greatly reduced, or at least that's the plan.\n\nThis has parallels with avoiding the use of CSS and Javascript inline in HTML. If for example you're allowing a user to customise a simple layout, then there isn't necessarily a need to have the user interact with the HTML itself as, depending on the circumstances of course.\n\nIf everything is inline and a jumble of CSS, JS and HTML I would argue this increases the chances of a particular style update being missed (as is the case with an agreement, where the risk of missing an update to a changeable term is increased if everything is within the body of the agreement).\n\n**Straining the analogy**\n\nYou could go as far as to say that the main body of an agreement is the view, the schedule with variables is the model, and the definitions section is the controller/router, providing the glue between the model and the view, defining how the terms in the schedule (price, payment terms, work period) are used in the view.\n\n![](/legalmvc.png \"It's MVC, but not as we know it, Jim\")\n\n**User feedback**\n\nA little trite, but both from a legal and a coding perspective, it's really important to have the results of your efforts reviewed by those who will be actually using the end result. Within my organisation, after I've drafted the document it will go out to the people who asked me to draft it in the first place for comments.\n\nAs a side-note, whether or not they'll give it a thorough read-through depends a) on the person's dedication to ensuring the terms of the proposed work are accurately reflected in the agreement and b) their trust in the abilities of the legal department!\n\nIn both cases you'll quickly find out what the important parts are and where improvements are desired, even if perhaps the full extent of the work isn't thoroughly assessed. If you're working for a services-based organisation, the expenses clause is generally the most important aspect of the agreement.\n\n**Modularity**\n\nMost agreements will have a set of standard clauses which you will find in most agreements, like choice of law, limitation of liability, assignment, waiver, and variation. Being able to slot these in and not have to worry about drafting new clauses each time takes time out the drafting process. This leaves time to focus on the elements unique to the agreement.\n\nIn the same way, when coding web applications, you will most likely have standard pieces of functionality like user authentication and file uploads, or frameworks like [Foundation](http://foundation.zurb.com/), [Bootstrap](http://getbootstrap.com/)and [Pure.CSS](http://purecss.io/) for the appearance of an app. Mozilla's Brick and Google's Polymer also open up the possibility of packaging up discrete elements of functionality.\n\n**But where do they differ?**\n\nIt's fair to say there's one pretty glaring way in which the two processes differ. If I want to draft a document I'm much more restricted in the way I can go out and grab existing examples that are free to use.\n\nThis is in stark contract to the many open source options that are available to help a person to quickly incorporate functionality into an app (at least in my experience in using [Node.js](http://nodejs.org) and [Express](http://expressjs.com)).\n\nSome folks including [Legal Zoom](http://www.legalzoom.com) and [Docracy](http://www.docracy.com) are taking steps to simplify the process for many users of legal services (in the case of the former and the latter) and to allow lawyers to provide and comment on agreements (in the case of the latter).\n\nHowever at present there isn't a widely-used service like Github where to extend the analogy and in the context of open source code, lawyers from different firms collaborate on improving documents used by all or used by many different people<sup id=\"fnref1\">[1](#fn1)</sup> (perhaps an overly broad definition) or lawyers might develop a set of wording internally and decide to release it for general consumption.\n\nWhether this will change in the future remains to be seen however, there are good reasons for this reduced participation:\n\n*   unlike software companies, law firms are less likely to gain goodwill as a result of making available clauses\n*   even standard clauses can need to be changed depending on the specific circumstances of a deal, reducing the benefit of open sourcing them in the first place\n*   confidentiality issues are more likely to be an issue\n*   perhaps most importantly, law firms act for clients who may take umbrage at releasing work (even if completely anonymised) as a third party could still benefit from the work, particularly bespoke drafting\n\nI'm not saying that many of these reasons cannot be overcome but at present the above barriers are sufficient to prevent wider participation by lawyers in open sourcing of legal documentation<sup id=\"fnref2\">[2](#fn2)</sup>.\n\nAs for the future, it will be interesting to see whether start-ups operating in the legal sector will be able to exert sufficient influence or make it attractive enough for large volumes of lawyers to start doing this.\n\n\n* * *\n\n1.  There are movements in certain niche areas where lawyers do collaborate to improve documents to a standard like [ISDA](http://www2.isda.org/) (for financial swaps and derivatives) and the [JCT](http://www.jctltd.co.uk/) for construction contracts but this is still a relatively closed system and is the exception rather than the rule. [↩](#fnref1)\n\n2.  One counter-example is the [Innovators Patent Agreement](https://github.com/twitter/innovators-patent-agreement/blob/master/innovators-patent-agreement.md).  [↩](#fnref2)\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file",
      "internal": {
        "content": "---\npath: '/Refactoring-from-jQuery-to-Angular.js'\ntitle: 'Refactoring from jQuery to Angular'\n---\n\n\nI recently transferred a site recently written predominantly using jQuery to Angular. The site is [Geophoto](http://geophoto.grabeh.net) and simply allows a user to be shown photos of a particular place. The user can click on a map, provide a location or let the browser geolocate them.\n\nI am the first to admit that the jQuery I had written previously was a bit of a jumble to say the least, having no real structure. Consequently it would be untruthful to say I was translating finely-tuned jQuery code to Angular and that jQuery was some kind of evil bogeyman to be expunged at all costs! If anything I am the bogeyman for being allowed to write jQuery in such an abominable manner!\n\njQuery can to an extent be moulded into whatever framework you want (to an extent!) but for a relative beginner the enforced compartmentalisation imposed by Angular has definitely helped me to produce code which I hope is cleaner and more straightforward to extend in the future.\n\nThere are a few issues that I faced in transferring but overall it was a relatively smooth experience. Although this is attributable in part to my experience in building another site with related functionality.\n\n**Google maps**\n\nTo recreate Google maps in Angular I simply wrapped all the necessary functionality in a Google maps-specific directive. However to limit the amount of functionality that interacted with the map, I had the directive $.broadcast out the necessary information to the parent controller.\n\nThat way the controller could simply take that data and use it, without getting too involved with the map directive:\n```javascript\n    $.$on('coords.change', function(e, l){     \n        flickr.search({ \n            lat: l.lat, \n            lon: l.lon, \n            tags: $.tag, \n            licenses: returnSelectedBoxesFilter($scope.licenses) })\n            .success(function(data){\n                $.arrayOfPhotos = data;\n            })\n            .error(function(err){\n                console.log(err)\n        })\n    })\n```\n**multiple select boxes**\n\nI use a range of select boxes in the app to allow the user to specify a range of licences applicable to their search. With jQuery I iterated over the boxes and extracted the selected ones to go to the server (Flickr's API takes an array of numbers corresponding to the different licences). The select boxes were then manually referenced in the HTML.\n\nIn Angular the process is similar however, I extracted out the data for each licence (name, type) into the related controller, and then used an ng-repeat in the HTML itself. This results in cleaner HTML plus by specifying a model for each box, Angular automatically keeps track of which boxes are updated.\n\nThen to extract the licences, a custom $filter is used in the controller to then return the above-mentioned array. Overall the presence of filters encourages you to switch data manipulation away from the controller and thus helping you reduce the amount of code in your controller (this is a good thing because often controllers can be a dumping ground for everything that's not in your HTML views).\n\n**geocoder services**\n\nWhen the user inputs a physical location, the app geocodes this and returns coordinates so a marker can be placed on the map. Conversely to provide a physical address when the user clicks the map, the coordinates are reverse-geocoded.\n\nIn both jQuery and Angular I use Google's geocoder service. With the latter however this has been extracted into a separate service which can then be injected into the controller.\n\nAs part of creating the service, I became more acquainted with promises and the $q functionality that Angular uses for promises. Although I'd used $http before, as it returns a promise automatically, I hadn't used $q before (although you can still use $q as part of $http for additional validation).\n\nUsing promises in services basically allows you to create a 'thennable' methods. When the method is called it will have a 'then' method to which you can provide two functions as arguments. The first what will happen in the event of a successful resolution (i.e. exposing the returned data), and the second in the event of a failed call (showing a suitable error message for example).\n\n    .factory('geoCoder', ['$q', function($q){\n             geocoder = new google.maps.Geocoder();\n              geocodeAddress: function(address){\n                     var deferred = $q.defer();\n                     geocoder.geocode({\n                        address: address\n                     }, function(results, status){\n                        if (status == google.maps.GeocoderStatus.OK){\n                            return deferred.resolve(results);\n                        }\n                        return deferred.reject();\n                     })\n                     return deferred.promise;\n                }\n            }\n            return geoCoder;\n        }])\n\n**geolocation via $window**\n\nRather than relying on window for HTML5 geolocation, I found you can use $window for this functionality which provides a suitable namespace rather than a global definition.\n\n**mg-paginator**\n\nDue to Flickr's terms of service, you can only display up to 30 photos per page. This meant that I had to create code to paginate the array of photo objects returned from the server.\n\nAlthough I got this done in jQuery, the code in Angular is much cleaner. Again, this may well be because from my study of Angular I have learnt cleaner ways of doing things. In jQuery for example in order to remove a 'Previous' button if at the start of an array, I tested the length of the array then removed the text of the button.\n\nWith Angular, I now use a function directly in the HTML linked to the ng-hide directive.\n\nAdditionally with Angular I was able to move the paginator specific code into a separate directive which makes the underlying HTML a little cleaner. I am still working out how to make the directive more reusable but having an isolated scope on the directive is certainly a move in the right direction (isolated scope means that your directive is not reliant on any parent scopes and only specific data/functions can be passed in via attributes on your directive (at least that is my understanding!)).\n\n**ng-pluralise**\n\nPreviously I worked directly with the DOM manipulating it dependent on the number of items in an array via conditional statements.\n\nNg-pluralise in its simplest form is a directive which allows you to map statements for the DOM to the length of an array, in the HTML code itself. This meant I could do away with direct manipulation and makes for a much cleaner way of doing things.\n\n**ng-repeat and automatic updating**\n\nThe app shows a list of places where users have searched for photos. Previously when each location was provided it would be added to the DOM manually.\n\nWith Angular I can push the location into a controller-based array and then use ng-repeat in the HTML itself, spitting out an element for each location. Because of the link to the controller the ng-repeat will update automatically when new locations are pushed into the array.\n\n    geoCoder.reverseGeocode(new google.maps.LatLng(l.lat, l.lon)).then(function(data){\n          $.locations.push(data[0].formatted_address);\n    })\n\n**Conclusion**\n\nThe code can be viewed in full [here on Github](https://github.com/grabbeh/geophoto). Whilst the overall length may not have changed, the structure has improved dramatically in my view.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "846657505a165da084fe0c050f9249d7",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Refactoring from jQuery to Angular",
        "path": "/Refactoring-from-jQuery-to-Angular.js",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\n\nI recently transferred a site recently written predominantly using jQuery to Angular. The site is [Geophoto](http://geophoto.grabeh.net) and simply allows a user to be shown photos of a particular place. The user can click on a map, provide a location or let the browser geolocate them.\n\nI am the first to admit that the jQuery I had written previously was a bit of a jumble to say the least, having no real structure. Consequently it would be untruthful to say I was translating finely-tuned jQuery code to Angular and that jQuery was some kind of evil bogeyman to be expunged at all costs! If anything I am the bogeyman for being allowed to write jQuery in such an abominable manner!\n\njQuery can to an extent be moulded into whatever framework you want (to an extent!) but for a relative beginner the enforced compartmentalisation imposed by Angular has definitely helped me to produce code which I hope is cleaner and more straightforward to extend in the future.\n\nThere are a few issues that I faced in transferring but overall it was a relatively smooth experience. Although this is attributable in part to my experience in building another site with related functionality.\n\n**Google maps**\n\nTo recreate Google maps in Angular I simply wrapped all the necessary functionality in a Google maps-specific directive. However to limit the amount of functionality that interacted with the map, I had the directive $.broadcast out the necessary information to the parent controller.\n\nThat way the controller could simply take that data and use it, without getting too involved with the map directive:\n```javascript\n    $.$on('coords.change', function(e, l){     \n        flickr.search({ \n            lat: l.lat, \n            lon: l.lon, \n            tags: $.tag, \n            licenses: returnSelectedBoxesFilter($scope.licenses) })\n            .success(function(data){\n                $.arrayOfPhotos = data;\n            })\n            .error(function(err){\n                console.log(err)\n        })\n    })\n```\n**multiple select boxes**\n\nI use a range of select boxes in the app to allow the user to specify a range of licences applicable to their search. With jQuery I iterated over the boxes and extracted the selected ones to go to the server (Flickr's API takes an array of numbers corresponding to the different licences). The select boxes were then manually referenced in the HTML.\n\nIn Angular the process is similar however, I extracted out the data for each licence (name, type) into the related controller, and then used an ng-repeat in the HTML itself. This results in cleaner HTML plus by specifying a model for each box, Angular automatically keeps track of which boxes are updated.\n\nThen to extract the licences, a custom $filter is used in the controller to then return the above-mentioned array. Overall the presence of filters encourages you to switch data manipulation away from the controller and thus helping you reduce the amount of code in your controller (this is a good thing because often controllers can be a dumping ground for everything that's not in your HTML views).\n\n**geocoder services**\n\nWhen the user inputs a physical location, the app geocodes this and returns coordinates so a marker can be placed on the map. Conversely to provide a physical address when the user clicks the map, the coordinates are reverse-geocoded.\n\nIn both jQuery and Angular I use Google's geocoder service. With the latter however this has been extracted into a separate service which can then be injected into the controller.\n\nAs part of creating the service, I became more acquainted with promises and the $q functionality that Angular uses for promises. Although I'd used $http before, as it returns a promise automatically, I hadn't used $q before (although you can still use $q as part of $http for additional validation).\n\nUsing promises in services basically allows you to create a 'thennable' methods. When the method is called it will have a 'then' method to which you can provide two functions as arguments. The first what will happen in the event of a successful resolution (i.e. exposing the returned data), and the second in the event of a failed call (showing a suitable error message for example).\n\n    .factory('geoCoder', ['$q', function($q){\n             geocoder = new google.maps.Geocoder();\n              geocodeAddress: function(address){\n                     var deferred = $q.defer();\n                     geocoder.geocode({\n                        address: address\n                     }, function(results, status){\n                        if (status == google.maps.GeocoderStatus.OK){\n                            return deferred.resolve(results);\n                        }\n                        return deferred.reject();\n                     })\n                     return deferred.promise;\n                }\n            }\n            return geoCoder;\n        }])\n\n**geolocation via $window**\n\nRather than relying on window for HTML5 geolocation, I found you can use $window for this functionality which provides a suitable namespace rather than a global definition.\n\n**mg-paginator**\n\nDue to Flickr's terms of service, you can only display up to 30 photos per page. This meant that I had to create code to paginate the array of photo objects returned from the server.\n\nAlthough I got this done in jQuery, the code in Angular is much cleaner. Again, this may well be because from my study of Angular I have learnt cleaner ways of doing things. In jQuery for example in order to remove a 'Previous' button if at the start of an array, I tested the length of the array then removed the text of the button.\n\nWith Angular, I now use a function directly in the HTML linked to the ng-hide directive.\n\nAdditionally with Angular I was able to move the paginator specific code into a separate directive which makes the underlying HTML a little cleaner. I am still working out how to make the directive more reusable but having an isolated scope on the directive is certainly a move in the right direction (isolated scope means that your directive is not reliant on any parent scopes and only specific data/functions can be passed in via attributes on your directive (at least that is my understanding!)).\n\n**ng-pluralise**\n\nPreviously I worked directly with the DOM manipulating it dependent on the number of items in an array via conditional statements.\n\nNg-pluralise in its simplest form is a directive which allows you to map statements for the DOM to the length of an array, in the HTML code itself. This meant I could do away with direct manipulation and makes for a much cleaner way of doing things.\n\n**ng-repeat and automatic updating**\n\nThe app shows a list of places where users have searched for photos. Previously when each location was provided it would be added to the DOM manually.\n\nWith Angular I can push the location into a controller-based array and then use ng-repeat in the HTML itself, spitting out an element for each location. Because of the link to the controller the ng-repeat will update automatically when new locations are pushed into the array.\n\n    geoCoder.reverseGeocode(new google.maps.LatLng(l.lat, l.lon)).then(function(data){\n          $.locations.push(data[0].formatted_address);\n    })\n\n**Conclusion**\n\nThe code can be viewed in full [here on Github](https://github.com/grabbeh/geophoto). Whilst the overall length may not have changed, the structure has improved dramatically in my view.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file",
      "internal": {
        "content": "---\npath: '/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean'\ntitle: 'Setting up HTTPS with Express Apps using Nginx and Digital Ocean'\n---\n\nThis is a quick list of the steps I took to get https up and running with a new app I've been working on called [Instok](https://instok.net). Although https is of course a good idea in general, the main motivation was to make sure I could use Stripe.\n\nWithout further ado, the steps are as follows (which are provided mainly as an aide memoire):\n\n*   Using OpenSSL, generate an RSA private key and a certificate signing request using [these instructions](http://www.rackspace.com/knowledge_center/article/generate-a-csr-with-openssl) (excerpted below).\n\n    openssl genrsa -out domain.com.key 2048\n\n    openssl req -new -key domain.com.key -out domain.csr\n\nIf you're planning on testing SSL you can also generate your own certificates using the below (after you've created your key and your CSR).\n\n    openssl x509 -req -in certrequest.csr -signkey privatekey.pem -out certificate.pem\n\n*   Purchase a security certificate (or get one for [free](https://konklone.com/post/switch-to-https-now-for-free)). I used [NameCheap](http://www.namecheap.com) as suggested by [Stripe](https://stripe.com/help/ssl). As part of the process, you will need to submit the certificate signing request generated in the above step.\n*   Once you have got access to your certificates (mine were emailed to me) copy and paste the certificate(s) into a txt file and store wherever they'll be needed on the VPS or elsewhere.\n\nIn addition to the main certificate, I was emailed an intermediate certificate. If this is the case for you, you can incorporate reference to this intermediate certificate in the 'ca' array referenced below in your node app.\n\n*   Incorporate a HTTPS server into your app, principally with the below code. If you're wondering, the pem format is nothing particularly special and can be enabled just be saving a file as 'rsakey.pem' for example provided it has -----BEGIN CERTIFICATE----- at the start and -----END CERTIFICATE----- you guessed it at the end. It is also important to retain the format they are provided in.\n\n    var options = {\n        // The RSA private key generated above\n        key: fs.readFileSync('./config/rsakey.pem'),\n        // The certicates sent to you by the certificate issuer\n        cert: fs.readFileSync('./config/main.pem'),\n        ca: [fs.readFileSync('./config/intermediate.pem')]\n    };\n\n    https.createServer(options, app).listen(port of your choosing);\n\nOne point that I got stuck on (for about a day alas) was that I initially had the https server listening on 443. I subsequently realised that this meant that Nginx could not use 443 to route requests as this was locked up by the Express app. This meant that Nginx couldn't do its job properly in terms of signposting requests to the various apps running on the VPS nor redirecting http requests to https.\n\n*   Once the app is running on your VPS, you'll need to update your nginx.conf file. The server module for https is similar to your usual modules for http but with a reference to port 443 and to the location of your RSA key and your main certificate as per the below. I found I didn't need to reference the intermediate certificate.\n\n    server {\n       listen 443 ssl default_server;\n\n       ssl_certificate      /path/to/your/app/main.pem;\n       ssl_certificate_key  /path/to/your/app/domain.pem;\n\n    }\n\n*   Once you reload the conf file, requests to [https://widget.com](https://widget.com) should be encrypted. You'll probably want to redirect http requests to https. This can be done in several ways but the most straight-forward method appears to be:\n\n    server {\n        listen 80;\n        server_name http://widget.com;\n        return 301 https://widget.com;\n    }\n\nAll in all I found the process relatively straightforward albeit with a few issues caused by my misunderstanding of how ports work.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "a377a2c4b088dc29ba99fcdbf396b651",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Setting up HTTPS with Express Apps using Nginx and Digital Ocean",
        "path": "/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nThis is a quick list of the steps I took to get https up and running with a new app I've been working on called [Instok](https://instok.net). Although https is of course a good idea in general, the main motivation was to make sure I could use Stripe.\n\nWithout further ado, the steps are as follows (which are provided mainly as an aide memoire):\n\n*   Using OpenSSL, generate an RSA private key and a certificate signing request using [these instructions](http://www.rackspace.com/knowledge_center/article/generate-a-csr-with-openssl) (excerpted below).\n\n    openssl genrsa -out domain.com.key 2048\n\n    openssl req -new -key domain.com.key -out domain.csr\n\nIf you're planning on testing SSL you can also generate your own certificates using the below (after you've created your key and your CSR).\n\n    openssl x509 -req -in certrequest.csr -signkey privatekey.pem -out certificate.pem\n\n*   Purchase a security certificate (or get one for [free](https://konklone.com/post/switch-to-https-now-for-free)). I used [NameCheap](http://www.namecheap.com) as suggested by [Stripe](https://stripe.com/help/ssl). As part of the process, you will need to submit the certificate signing request generated in the above step.\n*   Once you have got access to your certificates (mine were emailed to me) copy and paste the certificate(s) into a txt file and store wherever they'll be needed on the VPS or elsewhere.\n\nIn addition to the main certificate, I was emailed an intermediate certificate. If this is the case for you, you can incorporate reference to this intermediate certificate in the 'ca' array referenced below in your node app.\n\n*   Incorporate a HTTPS server into your app, principally with the below code. If you're wondering, the pem format is nothing particularly special and can be enabled just be saving a file as 'rsakey.pem' for example provided it has -----BEGIN CERTIFICATE----- at the start and -----END CERTIFICATE----- you guessed it at the end. It is also important to retain the format they are provided in.\n\n    var options = {\n        // The RSA private key generated above\n        key: fs.readFileSync('./config/rsakey.pem'),\n        // The certicates sent to you by the certificate issuer\n        cert: fs.readFileSync('./config/main.pem'),\n        ca: [fs.readFileSync('./config/intermediate.pem')]\n    };\n\n    https.createServer(options, app).listen(port of your choosing);\n\nOne point that I got stuck on (for about a day alas) was that I initially had the https server listening on 443. I subsequently realised that this meant that Nginx could not use 443 to route requests as this was locked up by the Express app. This meant that Nginx couldn't do its job properly in terms of signposting requests to the various apps running on the VPS nor redirecting http requests to https.\n\n*   Once the app is running on your VPS, you'll need to update your nginx.conf file. The server module for https is similar to your usual modules for http but with a reference to port 443 and to the location of your RSA key and your main certificate as per the below. I found I didn't need to reference the intermediate certificate.\n\n    server {\n       listen 443 ssl default_server;\n\n       ssl_certificate      /path/to/your/app/main.pem;\n       ssl_certificate_key  /path/to/your/app/domain.pem;\n\n    }\n\n*   Once you reload the conf file, requests to [https://widget.com](https://widget.com) should be encrypted. You'll probably want to redirect http requests to https. This can be done in several ways but the most straight-forward method appears to be:\n\n    server {\n        listen 80;\n        server_name http://widget.com;\n        return 301 https://widget.com;\n    }\n\nAll in all I found the process relatively straightforward albeit with a few issues caused by my misunderstanding of how ports work.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file",
      "internal": {
        "content": "---\npath: '/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes'\ntitle: 'Steps to improve Unity Ubuntu on Chromebook Crouton for developer purposes'\n---\n\nI recently bought an Acer C270 Chromebook and having undertaken the straightforward process of using Crouton to install Ubuntu/Unity, I found I had to take a few more steps to make the machine usable for Node.js development.\n\nI thought I'd outline the steps below I took. Clearly some steps may not be applicable depending on the preferred setup.\n\n**Terminal**\n\n    sudo apt-get install gnome-terminal\n\n**Google Chrome**\n\n    wget https://dl.google.com/linux/direct/google-chrome-  stable_current_amd64.deb\n\n    sudo dpkg -i google-chrome*.deb\n\n    sudo apt-get -f install\n\nYou may need to add '--user-data-dir' to the end of the /usr/bin/google-chrome file also so that Chrome runs.\n\nAlso 'python -c \"import gnomekeyring;gnomekeyring.change_password_sync('login', 'MYPASSWORD', '');\"' can be used to disable the request for a keyring password.\n\n**Node.js**\n\n    wget http://nodejs.org/dist/v0.10.22/node-v0.10.22.tar.gz\n\n    tar -xvzf node-v0.10.22.tar.gz\n\n    cd node-v0.10.22\n\n    apt-get install build-essential g++\n\n    ./configure\n\n    make\n\n    sudo make install\n\n    node -v\n\n**Git**\n\n    sudo apt-get install git\n\n**Fonts**\n\nThe font on Gnome Terminal was bunched up. This was fixed by installing a new font package as follows:\n\n    sudo apt-get install ttf-ubuntu-font-family\n\n**Sublime Text 2**\n\n    sudo add-apt-repository ppa:webupd8team/sublime-text-2\n\n    sudo apt-get update\n\n    sudo apt-get install sublime-text\n\n**Switching to Chromebook keyboard**\n\nThe key mappings in Ubuntu 12.04 are different to the default ones for the Chromebook. I therefore used xmodmap to update/switch around certain keys.\n\n    xmodmap -e \"keycode 94 shift = backslash bar\"\n\n    xmodmap -e \"keycode 51 shift = numbersign asciitilde\"\n\n    xmodmap -e  \"keycode 11 shift = 2 quotedbl\"\n\n    xmodmap -e \"keycode 48 shift = apostrophe at\"\n\nI also added a delete key and made the search key into caps lock with the following:\n\n    xmodmap -e \"keycode 22 shift = BackSpace Delete\"\n\n    xmodmap -e \"keycode 133 = Caps_Lock\"\n\nBear in mind that the above commands are session specific so to persist them you should create a file called '.xinitrc' file in your home directory, with 'xmodmap .Xmodmap' in, then xmodmap -pke > .Xmodmap in same directory to save revised .Xmodmap file in that directory.\n\nAlternatively, you can just call .xmodmap ~/Xmodmap on each session startup.\n\nOn remapping the Delete key I couldn't get the Alt + Backspace combination to work so used shift instead.\n\nI also mapped delete in Sublime Text 2 to shift + backspace by editing the existing binding in .sublime-keymap to the following:\n\n    { \"keys\": [\"shift+backspace\"], \"command\": \"right_delete\" }\n\nI'm very happy with the new Chromebook and the above additions have helped no end to make using Unity/Ubuntu via Crouton a good environment for me to develop in (maybe one day I'll master Vim but not today).\n",
        "type": "MarkdownRemark",
        "contentDigest": "2f630b2a4c1eafe7e9379b3573668d8b",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Steps to improve Unity Ubuntu on Chromebook Crouton for developer purposes",
        "path": "/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nI recently bought an Acer C270 Chromebook and having undertaken the straightforward process of using Crouton to install Ubuntu/Unity, I found I had to take a few more steps to make the machine usable for Node.js development.\n\nI thought I'd outline the steps below I took. Clearly some steps may not be applicable depending on the preferred setup.\n\n**Terminal**\n\n    sudo apt-get install gnome-terminal\n\n**Google Chrome**\n\n    wget https://dl.google.com/linux/direct/google-chrome-  stable_current_amd64.deb\n\n    sudo dpkg -i google-chrome*.deb\n\n    sudo apt-get -f install\n\nYou may need to add '--user-data-dir' to the end of the /usr/bin/google-chrome file also so that Chrome runs.\n\nAlso 'python -c \"import gnomekeyring;gnomekeyring.change_password_sync('login', 'MYPASSWORD', '');\"' can be used to disable the request for a keyring password.\n\n**Node.js**\n\n    wget http://nodejs.org/dist/v0.10.22/node-v0.10.22.tar.gz\n\n    tar -xvzf node-v0.10.22.tar.gz\n\n    cd node-v0.10.22\n\n    apt-get install build-essential g++\n\n    ./configure\n\n    make\n\n    sudo make install\n\n    node -v\n\n**Git**\n\n    sudo apt-get install git\n\n**Fonts**\n\nThe font on Gnome Terminal was bunched up. This was fixed by installing a new font package as follows:\n\n    sudo apt-get install ttf-ubuntu-font-family\n\n**Sublime Text 2**\n\n    sudo add-apt-repository ppa:webupd8team/sublime-text-2\n\n    sudo apt-get update\n\n    sudo apt-get install sublime-text\n\n**Switching to Chromebook keyboard**\n\nThe key mappings in Ubuntu 12.04 are different to the default ones for the Chromebook. I therefore used xmodmap to update/switch around certain keys.\n\n    xmodmap -e \"keycode 94 shift = backslash bar\"\n\n    xmodmap -e \"keycode 51 shift = numbersign asciitilde\"\n\n    xmodmap -e  \"keycode 11 shift = 2 quotedbl\"\n\n    xmodmap -e \"keycode 48 shift = apostrophe at\"\n\nI also added a delete key and made the search key into caps lock with the following:\n\n    xmodmap -e \"keycode 22 shift = BackSpace Delete\"\n\n    xmodmap -e \"keycode 133 = Caps_Lock\"\n\nBear in mind that the above commands are session specific so to persist them you should create a file called '.xinitrc' file in your home directory, with 'xmodmap .Xmodmap' in, then xmodmap -pke > .Xmodmap in same directory to save revised .Xmodmap file in that directory.\n\nAlternatively, you can just call .xmodmap ~/Xmodmap on each session startup.\n\nOn remapping the Delete key I couldn't get the Alt + Backspace combination to work so used shift instead.\n\nI also mapped delete in Sublime Text 2 to shift + backspace by editing the existing binding in .sublime-keymap to the following:\n\n    { \"keys\": [\"shift+backspace\"], \"command\": \"right_delete\" }\n\nI'm very happy with the new Chromebook and the above additions have helped no end to make using Unity/Ubuntu via Crouton a good environment for me to develop in (maybe one day I'll master Vim but not today).\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file",
      "internal": {
        "content": "---\npath: '/The-journey-from-curious-outsider-to-beginner'\ntitle: 'The Journey from curious outside to beginner'\n---\n\n\nStarting something completely new creates a whole load of different feelings. Hesitancy, fear, excitement and definitely for me the sense of being a little overwhelmed by it all (sometimes that's just getting out of bed in the morning).\n\nThe only way to keep me going is to try to make sure the positive emotions and benefits outweigh the negative feelings that can come with trying your hand at something new.\n\nYou might say I'm a little late to web development at 31\\. In some ways, I don't know why it took me so long to begin to ponder the mysteries of the internet, how everything fits together, and how the sites I see everyday are created. But life can have a habit of distracting you from interests, especially when you've got a full-time job.\n\nIt was only back in 2009 that I picked up a copy of [HTML, XHTML and CSS for dummies](http://www.amazon.co.uk/HTML-XHTML-All-Reference-Dummies/dp/0470186275). I worked through the sections in the title, but when I got to a section on PHP, I got stuck. I wasn't able to work out what was going on with the simple concept of booleans.\n\nI think I just wasn't able to get to a place where the positive emotions and excitement at learning outweighed by negative feelings at feeling intellectually inadequate. I just gave up. So although I was pleased that I'd put together a few static sites with html and css, I hadn't made much progress on learning how to create sites with any functionality.\n\nIt was a few years later, in 2011 when the interest in learning more about building sites rose above the other clutter in my brain. I bought a copy of Beginning Ruby([http://beginningruby.org/](http://beginningruby.org/)) by Peter Cooper.\n\nHowever, I didn't have anything to hang my learnings on, to say 'I want to do this, so what specifically do I need to learn to do that?' Although I was working my way through the book, it wasn't grabbing my interest as much as I'd hoped.\n\nThis was absolutely a failing on my part. At the end of a day at work or even during brief bouts of unemployment, I didn't have the drive to always open the book and keep on reading. Again, the sense of being all a bit overwhelmed took over. 'Where am I going with this? What is the point of it all?' Without any real pre-defined goal, it was too easy for me to get distracted to name but one.\n\nMoving forward again, it was back in early 2012 that my curiosity was piqued when I read about node.js. I think it was probably the lazy person in me that was interested to read about node.js. I was aware of JavaScript on the client being used to supplement html so it was interesting to read about node.js and JS on the server.\n\nAt the same time, [Code Academy](http://codecademy.com) was launched with free courses on how to learn JavaScript. The carrot technique worked well for me in terms of the drip-feed of rewards (thoughts of rats in a maze being rewarded for successfully navigating a maze spring to mind).\n\nStill, although I steamed through lots of the courses, for me there still seemed to be a disconnect between the exercises on Code Academy and sites that I used everyday.\n\nMy reading of the sacred texts of JS in the form of [Douglas Crockford's JavaScript: The Good Parts](http://www.crockford.com) and [Martijn Haverbeke's Eloquent Javascript](http://marijnhaverbeke.nl) also left me feeling a little overwhelmed and lost on how to actually build something.\n\nI think overall, the excitement of learning was still tempered by the feeling of separation from any tangible feeling of doing anything worthwhile and getting closer to building something worthwhile.\n\nI think the key point that's been missing from the above is the idea that to keep you learning, you need a project to focus on (I appreciate this may be a trite observation!).\n\nAlthough I'd had ideas over the years, I think they were perhaps on too grand a scale to make me think they were achievable. I'm not talking about manned missions to Mars here, more sites with a complexity too great for me to even begin to figure out where to start!.\n\nSo what enabled me to make the leap from the theory of JavaScript to building [Routebop](http://routebop.grabeh.net) (admittedly still a work in progress) site or [Geoflickr](http://geoflickr.jit.su)? I think it was mainly getting some ideas in the first place. Something which I could actually home in on and work towards achieving, with small steps so I could break down the code that was needed into smaller pieces.\n\nThe feeling of actually putting together some basic code and getting it to (eventually) work was incredible, punching-the-air worthy. Of course there was frustration and the negative feelings of sometimes wondering what the hell I was doing even trying to learn, but that was outweighed by the excitement.\n\nOn a basic level, I'd got to a place where the positive emotions and feelings of achievement were far outweighing the negativity.\n\nAs to my overall progress, I think it's fair to say that excitement at managing to cobble something together can turn into a feeling of apathy as you realise that what you've created isn't particularly complex. Clearly as a person's understanding of a subject increases, what were once mind-blowing discoveries can turn into simplistic concepts which lose their luster, at least in my case.\n\nFor example, whereas once I was excited at putting together Routebop, now all I see it as is simplistic manipulation of data using a basic CRUD interface.\n\nWhilst there's much to be said for putting together code that just works, I'm fairly certain mine doesn't conform to any design patterns, is not particularly maintainable nor (intentionally at least) makes use of closures, inheritance or with other concepts associated with well-written JavaScript. To an extent, accomplishments that were once exciting, are now just evidence that I haven't been able to grasp the more complex aspects of JavaScript.\n\nHaving said that, it's better to be in a position where you're pushing yourself to improve rather than resting on your laurels. To this end, I'm trying to learn more about JS frameworks for the client-side and incorporate libraries such as Caolan's [async](https://github.com/caolan/async) on the server-side.\n\nEventually, maybe some time in the future, I can make the leap from beginner to someone conversant with the more advanced features of JavaScript.\n\nThe code for Routebop and Geoflickr can be found [here](https://github.com/Grabbeh/routebop) and [here](https://github.com/Grabbeh/geoflickr) for the curious. Pull requests are welcome :)\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "b1eaa845b7af3183eff02b69d06569d5",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "The Journey from curious outside to beginner",
        "path": "/The-journey-from-curious-outsider-to-beginner",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\n\nStarting something completely new creates a whole load of different feelings. Hesitancy, fear, excitement and definitely for me the sense of being a little overwhelmed by it all (sometimes that's just getting out of bed in the morning).\n\nThe only way to keep me going is to try to make sure the positive emotions and benefits outweigh the negative feelings that can come with trying your hand at something new.\n\nYou might say I'm a little late to web development at 31\\. In some ways, I don't know why it took me so long to begin to ponder the mysteries of the internet, how everything fits together, and how the sites I see everyday are created. But life can have a habit of distracting you from interests, especially when you've got a full-time job.\n\nIt was only back in 2009 that I picked up a copy of [HTML, XHTML and CSS for dummies](http://www.amazon.co.uk/HTML-XHTML-All-Reference-Dummies/dp/0470186275). I worked through the sections in the title, but when I got to a section on PHP, I got stuck. I wasn't able to work out what was going on with the simple concept of booleans.\n\nI think I just wasn't able to get to a place where the positive emotions and excitement at learning outweighed by negative feelings at feeling intellectually inadequate. I just gave up. So although I was pleased that I'd put together a few static sites with html and css, I hadn't made much progress on learning how to create sites with any functionality.\n\nIt was a few years later, in 2011 when the interest in learning more about building sites rose above the other clutter in my brain. I bought a copy of Beginning Ruby([http://beginningruby.org/](http://beginningruby.org/)) by Peter Cooper.\n\nHowever, I didn't have anything to hang my learnings on, to say 'I want to do this, so what specifically do I need to learn to do that?' Although I was working my way through the book, it wasn't grabbing my interest as much as I'd hoped.\n\nThis was absolutely a failing on my part. At the end of a day at work or even during brief bouts of unemployment, I didn't have the drive to always open the book and keep on reading. Again, the sense of being all a bit overwhelmed took over. 'Where am I going with this? What is the point of it all?' Without any real pre-defined goal, it was too easy for me to get distracted to name but one.\n\nMoving forward again, it was back in early 2012 that my curiosity was piqued when I read about node.js. I think it was probably the lazy person in me that was interested to read about node.js. I was aware of JavaScript on the client being used to supplement html so it was interesting to read about node.js and JS on the server.\n\nAt the same time, [Code Academy](http://codecademy.com) was launched with free courses on how to learn JavaScript. The carrot technique worked well for me in terms of the drip-feed of rewards (thoughts of rats in a maze being rewarded for successfully navigating a maze spring to mind).\n\nStill, although I steamed through lots of the courses, for me there still seemed to be a disconnect between the exercises on Code Academy and sites that I used everyday.\n\nMy reading of the sacred texts of JS in the form of [Douglas Crockford's JavaScript: The Good Parts](http://www.crockford.com) and [Martijn Haverbeke's Eloquent Javascript](http://marijnhaverbeke.nl) also left me feeling a little overwhelmed and lost on how to actually build something.\n\nI think overall, the excitement of learning was still tempered by the feeling of separation from any tangible feeling of doing anything worthwhile and getting closer to building something worthwhile.\n\nI think the key point that's been missing from the above is the idea that to keep you learning, you need a project to focus on (I appreciate this may be a trite observation!).\n\nAlthough I'd had ideas over the years, I think they were perhaps on too grand a scale to make me think they were achievable. I'm not talking about manned missions to Mars here, more sites with a complexity too great for me to even begin to figure out where to start!.\n\nSo what enabled me to make the leap from the theory of JavaScript to building [Routebop](http://routebop.grabeh.net) (admittedly still a work in progress) site or [Geoflickr](http://geoflickr.jit.su)? I think it was mainly getting some ideas in the first place. Something which I could actually home in on and work towards achieving, with small steps so I could break down the code that was needed into smaller pieces.\n\nThe feeling of actually putting together some basic code and getting it to (eventually) work was incredible, punching-the-air worthy. Of course there was frustration and the negative feelings of sometimes wondering what the hell I was doing even trying to learn, but that was outweighed by the excitement.\n\nOn a basic level, I'd got to a place where the positive emotions and feelings of achievement were far outweighing the negativity.\n\nAs to my overall progress, I think it's fair to say that excitement at managing to cobble something together can turn into a feeling of apathy as you realise that what you've created isn't particularly complex. Clearly as a person's understanding of a subject increases, what were once mind-blowing discoveries can turn into simplistic concepts which lose their luster, at least in my case.\n\nFor example, whereas once I was excited at putting together Routebop, now all I see it as is simplistic manipulation of data using a basic CRUD interface.\n\nWhilst there's much to be said for putting together code that just works, I'm fairly certain mine doesn't conform to any design patterns, is not particularly maintainable nor (intentionally at least) makes use of closures, inheritance or with other concepts associated with well-written JavaScript. To an extent, accomplishments that were once exciting, are now just evidence that I haven't been able to grasp the more complex aspects of JavaScript.\n\nHaving said that, it's better to be in a position where you're pushing yourself to improve rather than resting on your laurels. To this end, I'm trying to learn more about JS frameworks for the client-side and incorporate libraries such as Caolan's [async](https://github.com/caolan/async) on the server-side.\n\nEventually, maybe some time in the future, I can make the leap from beginner to someone conversant with the more advanced features of JavaScript.\n\nThe code for Routebop and Geoflickr can be found [here](https://github.com/Grabbeh/routebop) and [here](https://github.com/Grabbeh/geoflickr) for the curious. Pull requests are welcome :)\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file",
      "internal": {
        "content": "---\npath: '/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js'\ntitle: 'Automated publishing on a VPS using Drafting webhooks and Node.js'\n---\n\nDraftin.com is a great tool I've been using lately to do some writing. Whilst I'm not utilising many of its more advanced features, the care and attention that its creator has put into the product shines through.\n\nOnce I'd written something my previous process of getting onto this site was to copy and paste the contents into a template file within the VPS I'm using to host this blog, and then name it appropriately. Although this isn't a particularly burdensome process, I thought there may be a simpler process.\n\nHaving a gander at Draftin I saw reference to [Webhooks](https://draftin.com/features#webhooks). Webhooks give you the ability to specify a url to which the content will be published using a simple POST request.\n\nI thought it would be interesting to try to integrate this into the VPS so you could post data and automatically create a html file in the folder from which the html files making up this blog are served from via Nginx.\n\nI initially created a basic Express server to test the data that was being sent. After some issues with accessing the data, I realised I need to parse the JSON to make it accessible.\n\nOnce that was done, I wrote the 'content_html' to a file in the relevant folder. However the issue was obviously that the only content being posted was the blog post itself. In addition to the content, it also needed surrounding container elements and the head element to specify css etc.\n\nTo remedy this, I created a template.html file which is then read in when post data is received. Using the excellent [Cheerio](https://github.com/MatthewMueller/cheerio) I then load in the template html and then manipulate it using simple jQuery-like functionality to add in a title and the content from the POST data from Draftin.\n\nOnce completed, the amended file is then saved as a new file with the stated title then accessible at blog.grabeh.net/[title]. Draftin also allows you to provide a location url in your response which is then captured by Draftin which is then displayed by your post.\n\nThe whole basic Express server is below for the curious. As the documentation on Draftin notes, the URL used to post data to should be sufficiently obscure.\n\n\n      var express = require('express'),\n        fs = require('fs'),\n        cheerio = require('cheerio'),\n        app = express()\n      app.configure(function () {\n        app.use(express.bodyParser())\n        app.use(app.router)\n      })\n      app.post('/', function (req, res) {\n        var payload = req.body.payload\n        var parsedResponse = JSON.parse(payload)\n        var title = parsedResponse.name\n        var htitle = title.replace(/\\s+/g, '-').toLowerCase()\n        var parsedhtml = parsedResponse.content_html\n        fs.readFile('/usr/local/nginx/html/blog/template.html', function (err, data) {\n          $ = cheerio.load(data)\n          $('h3').text(title)\n          $('#textbody').html(parsedhtml)\n          var updatedhtml = $.html()\n          fs.writeFile(\n            '/usr/local/nginx/html/blog/' + htitle + '.html',\n            updatedhtml,\n            function (err) {\n              if (!err) {\n                res.set('location', 'http://blog.grabeh.net/' + htitle)\n                res.send()\n              }\n            }\n          )\n        })\n      })\n      app.listen(3010)\n\nI do need to resolve a few minor points like inserting a title in the head and also updating the index.html of the blog, but I think the above system creates a nice flow for automatically posting content to the blog from Draftin.\n\nThe only issue now of course is to keep focused on writing in the first place.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "a7c7a1807b3e608a7c5062213699b3ab",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Automated publishing on a VPS using Drafting webhooks and Node.js",
        "path": "/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nDraftin.com is a great tool I've been using lately to do some writing. Whilst I'm not utilising many of its more advanced features, the care and attention that its creator has put into the product shines through.\n\nOnce I'd written something my previous process of getting onto this site was to copy and paste the contents into a template file within the VPS I'm using to host this blog, and then name it appropriately. Although this isn't a particularly burdensome process, I thought there may be a simpler process.\n\nHaving a gander at Draftin I saw reference to [Webhooks](https://draftin.com/features#webhooks). Webhooks give you the ability to specify a url to which the content will be published using a simple POST request.\n\nI thought it would be interesting to try to integrate this into the VPS so you could post data and automatically create a html file in the folder from which the html files making up this blog are served from via Nginx.\n\nI initially created a basic Express server to test the data that was being sent. After some issues with accessing the data, I realised I need to parse the JSON to make it accessible.\n\nOnce that was done, I wrote the 'content_html' to a file in the relevant folder. However the issue was obviously that the only content being posted was the blog post itself. In addition to the content, it also needed surrounding container elements and the head element to specify css etc.\n\nTo remedy this, I created a template.html file which is then read in when post data is received. Using the excellent [Cheerio](https://github.com/MatthewMueller/cheerio) I then load in the template html and then manipulate it using simple jQuery-like functionality to add in a title and the content from the POST data from Draftin.\n\nOnce completed, the amended file is then saved as a new file with the stated title then accessible at blog.grabeh.net/[title]. Draftin also allows you to provide a location url in your response which is then captured by Draftin which is then displayed by your post.\n\nThe whole basic Express server is below for the curious. As the documentation on Draftin notes, the URL used to post data to should be sufficiently obscure.\n\n\n      var express = require('express'),\n        fs = require('fs'),\n        cheerio = require('cheerio'),\n        app = express()\n      app.configure(function () {\n        app.use(express.bodyParser())\n        app.use(app.router)\n      })\n      app.post('/', function (req, res) {\n        var payload = req.body.payload\n        var parsedResponse = JSON.parse(payload)\n        var title = parsedResponse.name\n        var htitle = title.replace(/\\s+/g, '-').toLowerCase()\n        var parsedhtml = parsedResponse.content_html\n        fs.readFile('/usr/local/nginx/html/blog/template.html', function (err, data) {\n          $ = cheerio.load(data)\n          $('h3').text(title)\n          $('#textbody').html(parsedhtml)\n          var updatedhtml = $.html()\n          fs.writeFile(\n            '/usr/local/nginx/html/blog/' + htitle + '.html',\n            updatedhtml,\n            function (err) {\n              if (!err) {\n                res.set('location', 'http://blog.grabeh.net/' + htitle)\n                res.send()\n              }\n            }\n          )\n        })\n      })\n      app.listen(3010)\n\nI do need to resolve a few minor points like inserting a title in the head and also updating the index.html of the blog, but I think the above system creates a nice flow for automatically posting content to the blog from Draftin.\n\nThe only issue now of course is to keep focused on writing in the first place.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file",
      "internal": {
        "content": "---\npath: '/The-myth-of-mandatory-trade-mark-enforcement'\ntitle: 'The myth of mandatory trade mark enforcement'\n---\n\nTrade mark disputes pop up all the time. Often it's a David v Goliath affair with a large incumbent with an equally large legal budget seeking to squish a plucky start-up.\n\nIn some cases, the Goliath can attempt to use its registered trade marks to oppress an upstart providing goods or services in an area completely unrelated to it.\n\nSome may see this kind of action as completely unreasonable on the basis that there couldn't conceivably be any confusion or intention to take advantage of the reputation of the incumbent.\n\nOthers might comment that a trade mark owner is required to enforce their trade marks otherwise risk losing the ability to enforce them in the future or as is sometimes mooted lose the trade mark altogether.\n\nThe first thing to say is that a trade mark owner is not going to lose their trade mark through a failure to enforce their trade mark right.\n\nFailure to enforce may result in the trade mark becoming diluted and generic, in which case a third party may seek to invalidate the registration, but this process would never happen automatically.\n\nSecondly, a trade mark owner will not lose their ability to enforce their trade mark rights simply because they do not enforce all potential misuses. This is because all potential misuses are not the same and a perceived infringement does not always equate to a cast-iron case against the alleged infringer.\n\nSome examples may be useful.\n\n**_Example A_**\n\n> Behemoth Enterprises runs a hugely successful business manufacturing hardware. Behemoth becomes aware of consulting company using the 'Bohomoth' mark providing advice to companies on hardware.\n\n**_Example B_**\n\n> Behemoth again becomes aware of a company using the Bohomoth mark but this time in the field of kindergarten services\n\nIn example A, action would be entirely justified in taking action even though Behemoth is not in the field of consulting services directly but there is a clear likelihood of confusion arising in the minds of consumers as to whether the consulting firm is linked to the goods supplier.\n\nIt's also worth remembering that a trade mark owner is also not restricted from taking action for just identical marks but also for similar marks (hence the Behemoth vs Bohomoth example).\n\nIn example B, the grounds for taking action would be far more limited. It is not so clear cut however at its heart, there is a very low chance that a potential customer of a kindergarten would consider that there is a connection between the kindergarten and the hardware manufacturer<sup id=\"fnref1\">[1](#fn1)</sup> even one where Arnie works.\n\n![](/arnie.jpg)\n\nWhilst it is appreciated that a trade mark owner does not always have to pursue only those infringements it has a cast-iron case in relation to, there is certainly room for some nuance on the part of the trade mark owner in determining which perceived infringements to pursue.\n\nAt the same time, it is not a requirement that the trade mark owner is under a duty to pursue each and every infringement.\n\nSupport for the concept that a trade mark owner is not obliged to pursue every perceived infringement can be found in [this USPTO report to Congress from 2011](http://www.uspto.gov/ip/TMLitigationReport_final_2011April27.pdf). In their report whilst noting that there is an affirmative obligation to protect a trade mark from misuse, they noted that (at page 6):\n\n>A trademark owner is not required to object to all unauthorized uses that might conflict, for not everys third-party use poses the same risk of eroding distinctiveness in the marketplace.\n\nAdditionally, they included reference to the case of Chicago Bears Football Club Inc. v. 12th Man/Tennesse LLC, 83 USPQ2d 1073, 1082 (TTAB 2007), quoting McDonald's Corp. v. McKinley, 13 USPQ2d 1895, 1899-1900 (TTAB 1989) from the USPTO's Trademark Trial and Appeal Board:\n\n>[I]t is entirely reasonable for the [trademark owner] to object to the use of certain marks in use on some goods which it believes would conflict with the use of its marks . . . while not objecting to use of a similar mark on other goods which it does not believe would conflict with its own use.\n\nAs with the examples above, failing to pursue example B above, is unlikely to result in a reduction of the distinctiveness of the Behemoth mark for hardware manufacture and it is not reasonable to hold a belief that usage of Bohomoth for kindergartens would conflict.<sup id=\"fnref2\">[2](#fn2)</sup>\n\nIn any event it's clear that the affirmative duty is not to pursue each and every infringement but to pursue infringements which could erode distinctiveness.\n\nOf course what cannot be ignored is that in practice there may be little difference between the two due to the determination being in the eye of beholder however a line should be drawn somewhere.\n\nIn reality it would be sensible in drawing that line to take into account the likelihood of a successful lawsuit and the potential for erosion of distinctiveness before taking the decision to send out a cease and desist letter.\n\nAppropriate enforcement is a balancing act of taking action against all cases where there is a tangible threat to the trade mark owner's mark but at the same time not making threats which could be easily be rebuffed if the matter came to court or which at the very least risk attracting the ire of the court of public opinion.\n\n<div class=\"footnotes\">\n\n* * *\n\n1.  The test for confusion is generally used where Party A's goods are similar/identical to Party B's and Party A is using a similar/identical mark. In addition to confusion, Party B can generally take action where Party A seeks to take advantage of the goodwill Party B has in its mark even where the goods are completely dissimilar. This could be the case with Bohomoth Kindergartens however, it is submitted that it would be very difficult for Behemoth to show Bohomoth is attempting to take advantage of the goodwill in the Behemoth name. [↩](#fnref1)\n\n2.  On a related note, acquiescence is another potential doctrine to consider, however failing to take action in example B would not constitute a waiver of a right to take action against example A. [↩](#fnref2)\n</div>\n",
        "type": "MarkdownRemark",
        "contentDigest": "0e2f1403937682d89b87b595dd00a4f9",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "The myth of mandatory trade mark enforcement",
        "path": "/The-myth-of-mandatory-trade-mark-enforcement",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nTrade mark disputes pop up all the time. Often it's a David v Goliath affair with a large incumbent with an equally large legal budget seeking to squish a plucky start-up.\n\nIn some cases, the Goliath can attempt to use its registered trade marks to oppress an upstart providing goods or services in an area completely unrelated to it.\n\nSome may see this kind of action as completely unreasonable on the basis that there couldn't conceivably be any confusion or intention to take advantage of the reputation of the incumbent.\n\nOthers might comment that a trade mark owner is required to enforce their trade marks otherwise risk losing the ability to enforce them in the future or as is sometimes mooted lose the trade mark altogether.\n\nThe first thing to say is that a trade mark owner is not going to lose their trade mark through a failure to enforce their trade mark right.\n\nFailure to enforce may result in the trade mark becoming diluted and generic, in which case a third party may seek to invalidate the registration, but this process would never happen automatically.\n\nSecondly, a trade mark owner will not lose their ability to enforce their trade mark rights simply because they do not enforce all potential misuses. This is because all potential misuses are not the same and a perceived infringement does not always equate to a cast-iron case against the alleged infringer.\n\nSome examples may be useful.\n\n**_Example A_**\n\n> Behemoth Enterprises runs a hugely successful business manufacturing hardware. Behemoth becomes aware of consulting company using the 'Bohomoth' mark providing advice to companies on hardware.\n\n**_Example B_**\n\n> Behemoth again becomes aware of a company using the Bohomoth mark but this time in the field of kindergarten services\n\nIn example A, action would be entirely justified in taking action even though Behemoth is not in the field of consulting services directly but there is a clear likelihood of confusion arising in the minds of consumers as to whether the consulting firm is linked to the goods supplier.\n\nIt's also worth remembering that a trade mark owner is also not restricted from taking action for just identical marks but also for similar marks (hence the Behemoth vs Bohomoth example).\n\nIn example B, the grounds for taking action would be far more limited. It is not so clear cut however at its heart, there is a very low chance that a potential customer of a kindergarten would consider that there is a connection between the kindergarten and the hardware manufacturer<sup id=\"fnref1\">[1](#fn1)</sup> even one where Arnie works.\n\n![](/arnie.jpg)\n\nWhilst it is appreciated that a trade mark owner does not always have to pursue only those infringements it has a cast-iron case in relation to, there is certainly room for some nuance on the part of the trade mark owner in determining which perceived infringements to pursue.\n\nAt the same time, it is not a requirement that the trade mark owner is under a duty to pursue each and every infringement.\n\nSupport for the concept that a trade mark owner is not obliged to pursue every perceived infringement can be found in [this USPTO report to Congress from 2011](http://www.uspto.gov/ip/TMLitigationReport_final_2011April27.pdf). In their report whilst noting that there is an affirmative obligation to protect a trade mark from misuse, they noted that (at page 6):\n\n>A trademark owner is not required to object to all unauthorized uses that might conflict, for not everys third-party use poses the same risk of eroding distinctiveness in the marketplace.\n\nAdditionally, they included reference to the case of Chicago Bears Football Club Inc. v. 12th Man/Tennesse LLC, 83 USPQ2d 1073, 1082 (TTAB 2007), quoting McDonald's Corp. v. McKinley, 13 USPQ2d 1895, 1899-1900 (TTAB 1989) from the USPTO's Trademark Trial and Appeal Board:\n\n>[I]t is entirely reasonable for the [trademark owner] to object to the use of certain marks in use on some goods which it believes would conflict with the use of its marks . . . while not objecting to use of a similar mark on other goods which it does not believe would conflict with its own use.\n\nAs with the examples above, failing to pursue example B above, is unlikely to result in a reduction of the distinctiveness of the Behemoth mark for hardware manufacture and it is not reasonable to hold a belief that usage of Bohomoth for kindergartens would conflict.<sup id=\"fnref2\">[2](#fn2)</sup>\n\nIn any event it's clear that the affirmative duty is not to pursue each and every infringement but to pursue infringements which could erode distinctiveness.\n\nOf course what cannot be ignored is that in practice there may be little difference between the two due to the determination being in the eye of beholder however a line should be drawn somewhere.\n\nIn reality it would be sensible in drawing that line to take into account the likelihood of a successful lawsuit and the potential for erosion of distinctiveness before taking the decision to send out a cease and desist letter.\n\nAppropriate enforcement is a balancing act of taking action against all cases where there is a tangible threat to the trade mark owner's mark but at the same time not making threats which could be easily be rebuffed if the matter came to court or which at the very least risk attracting the ire of the court of public opinion.\n\n<div class=\"footnotes\">\n\n* * *\n\n1.  The test for confusion is generally used where Party A's goods are similar/identical to Party B's and Party A is using a similar/identical mark. In addition to confusion, Party B can generally take action where Party A seeks to take advantage of the goodwill Party B has in its mark even where the goods are completely dissimilar. This could be the case with Bohomoth Kindergartens however, it is submitted that it would be very difficult for Behemoth to show Bohomoth is attempting to take advantage of the goodwill in the Behemoth name. [↩](#fnref1)\n\n2.  On a related note, acquiescence is another potential doctrine to consider, however failing to take action in example B would not constitute a waiver of a right to take action against example A. [↩](#fnref2)\n</div>\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file",
      "internal": {
        "content": "---\npath: '/Image-uploads-and-resizing-with-Transloadit'\ntitle: 'Image uploads and resizing with Transloadit'\n---\n\nGiving people the ability to upload photos has been on my mind for a while because photos are a great way to help evoke memories and also to give others a better idea of what a route involves (although I guess there’s always Google Street View for that).\n\nI had pondered different methods to upload images and in the end I’m now using a third party service in the form of [Transloadit](http://www.transloadit.com). Before starting with image uploads I was a little hesitant that it would be a task too complex for my beginner level experience so although I have previously preferred at certain times to build functionality myself, I was definitely interested in seeing how a third party service could make things easier for me.\n\nTransloadit has its own servers which you can use for image processing (in Routebop’s case resizing the image to a thumbnail before uploading both to an S3 instance. In terms of the front-end code, and on a basic level, Transloadit requires you to incorporate hidden fields in your file upload forms which allow you to send data to Transloadit’s servers detailing how you want images/media to be processed. This process blocks the normal submission of the form and once processed, links to the processed images are returned in a hidden form field and the whole form is then submitted to your server as usual.\n\nHowever, because Routebop just deals with submitting data via jQuery’s .ajax functionality, I used the Transloadit’s handily provided jQuery plugin to disable automatic submission of the form following Transloadit’s completion of its magic. Instead, on completion, the urls for the images as stored on S3 are firstly used to render a thumbnail on the routebop.com/new page and also stored in an object and pushed into an images array, ready to be submitted with the rest of the route when the user is ready.\n\n    $('#MyForm').transloadit({ \n      wait: true, \n      autoSubmit: false, \n      modal: false, \n      onProgress: function(bytesReceived, bytesExpected){ \n        $('#progress').text(\"Progress: \" + (bytesReceived / bytesExpected * 100)\n        .toFixed(2)+'%'); \n      }, \n      onSuccess: function(assembly){ \n        $('#progress').text(\"\"); \n        var thumburl = assembly.results.thumb[0].url; \n        var mainurl = assembly.results[':original'][0].url; \n        $('#thumb').append(\"\" + \"x\"); \n        $('#thumb').find('span').addClass('removeImage'); \n        var imgUrls = {}; \n        imgUrls['thumburl'] = thumburl; \n        imgUrls['mainurl'] = mainurl; \n        images.push(imgUrls); \n        } \n    }); \n\nIn addition to adding the thumbnail from Transloadit into the page, I also wanted to add a 'x' button so users could remove the offending image. Mainly because I was lazy, instead of using an image of a red cross (to be clicked when a user wants to remove an uploaded image), I created a separate span and used a negative margin to push the <span>x</span> over the image in question. It doesn’t look quite as good as an image but I think it doesn’t look so bad (a fully circular span would be nice!). The code for that CSS is below.\n\n    .removeImage {\n      font-weight: bold;\n      background: red;\n      color: white;\n      font-family: arial;\n      font-size: 16px;\n      margin-top: 0px;\n      margin-right: 12px;\n      margin-left: -8px;\n      margin-bottom: 7px;\n      border-radius: 15px;\n      padding: 3px;\n    }\n\nOverall, I found incorporating Transloadit very straightforward and although I suspect I’m using it in a slightly different manner than intended, it’s working out well for me. Although it would definitely be interesting to explore building functionality to upload files directly to my S3 instance.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "035075adbef62ee931a80bae3db3de27",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Image uploads and resizing with Transloadit",
        "path": "/Image-uploads-and-resizing-with-Transloadit",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nGiving people the ability to upload photos has been on my mind for a while because photos are a great way to help evoke memories and also to give others a better idea of what a route involves (although I guess there’s always Google Street View for that).\n\nI had pondered different methods to upload images and in the end I’m now using a third party service in the form of [Transloadit](http://www.transloadit.com). Before starting with image uploads I was a little hesitant that it would be a task too complex for my beginner level experience so although I have previously preferred at certain times to build functionality myself, I was definitely interested in seeing how a third party service could make things easier for me.\n\nTransloadit has its own servers which you can use for image processing (in Routebop’s case resizing the image to a thumbnail before uploading both to an S3 instance. In terms of the front-end code, and on a basic level, Transloadit requires you to incorporate hidden fields in your file upload forms which allow you to send data to Transloadit’s servers detailing how you want images/media to be processed. This process blocks the normal submission of the form and once processed, links to the processed images are returned in a hidden form field and the whole form is then submitted to your server as usual.\n\nHowever, because Routebop just deals with submitting data via jQuery’s .ajax functionality, I used the Transloadit’s handily provided jQuery plugin to disable automatic submission of the form following Transloadit’s completion of its magic. Instead, on completion, the urls for the images as stored on S3 are firstly used to render a thumbnail on the routebop.com/new page and also stored in an object and pushed into an images array, ready to be submitted with the rest of the route when the user is ready.\n\n    $('#MyForm').transloadit({ \n      wait: true, \n      autoSubmit: false, \n      modal: false, \n      onProgress: function(bytesReceived, bytesExpected){ \n        $('#progress').text(\"Progress: \" + (bytesReceived / bytesExpected * 100)\n        .toFixed(2)+'%'); \n      }, \n      onSuccess: function(assembly){ \n        $('#progress').text(\"\"); \n        var thumburl = assembly.results.thumb[0].url; \n        var mainurl = assembly.results[':original'][0].url; \n        $('#thumb').append(\"\" + \"x\"); \n        $('#thumb').find('span').addClass('removeImage'); \n        var imgUrls = {}; \n        imgUrls['thumburl'] = thumburl; \n        imgUrls['mainurl'] = mainurl; \n        images.push(imgUrls); \n        } \n    }); \n\nIn addition to adding the thumbnail from Transloadit into the page, I also wanted to add a 'x' button so users could remove the offending image. Mainly because I was lazy, instead of using an image of a red cross (to be clicked when a user wants to remove an uploaded image), I created a separate span and used a negative margin to push the <span>x</span> over the image in question. It doesn’t look quite as good as an image but I think it doesn’t look so bad (a fully circular span would be nice!). The code for that CSS is below.\n\n    .removeImage {\n      font-weight: bold;\n      background: red;\n      color: white;\n      font-family: arial;\n      font-size: 16px;\n      margin-top: 0px;\n      margin-right: 12px;\n      margin-left: -8px;\n      margin-bottom: 7px;\n      border-radius: 15px;\n      padding: 3px;\n    }\n\nOverall, I found incorporating Transloadit very straightforward and although I suspect I’m using it in a slightly different manner than intended, it’s working out well for me. Although it would definitely be interesting to explore building functionality to upload files directly to my S3 instance.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file",
      "internal": {
        "content": "---\npath: '/Learnings-from-building-a-basic-Angular.js-app'\ntitle: 'Learnings from building a basic Angular.js app'\n---\n\nI have recently been tinkering with Angular.js to build a basic application called Instok. Although I haven't really scratched the surface when it comes to Angular.js, I definitely learned a good amount about the framework and thought I'd share that in a post:\n\n**Authentication**\n\nHaving worked with pure-server side authentication (in the sense that all authentication happened on the server, and if a request was successful there would be a redirect with a full page re-render) it was definitely a hurdle for me to manage authentication in Angular.\n\nThe main issue was that instead of there being a full page re-render on authentication, the server would notify the client that authentication was successful.\n\nHowever, initially I tried to stick as closely as possible to the existing server-side method as possible. This involved setting the user as a local variable (using app.locals in Express) which would be passed when the initial index.html template was rendered on the client side.\n\nHowever, this technique proved to be a little problematic for me on the basis that when a user logged out on the client-side, the change did not immediately follow through in the entirety of the app.\n\nSpecifically, conditional views using ng-show would continue to display as if the user was still logged in. I think this may have been solved with a full page re-render but on the basis that I was using ng-view to display the bulk of the app (with the ng-show elements sitting outside the ng-view), I didn't necessarily want to do this.\n\nI think I then read about an alternative which would be to create a service to fetch the authenticated user from the server on a successful authentication. As a result, when the user logs in, on a successful request, the server responds with a 200 status, and the client then subsequently requests the logged in user's details.\n\nOn a successful request, the user is then attached to the rootScope, and therefore accessible through the Angular app.\n\nAs a side note, I tried to simply send the authed user back with the login request, but for reasons I couldn't fathom this didn't work as desired. I also realise I should potentially use http interceptors to deal with the incoming requests, rather than waiting to deal with them in a service however at this stage I think I'm just pleased I've got authentication to work ok!\n\n**Restricting routes**\n\nInitially in each controller for a particular route that I wanted to restrict access to I would make a call to the server to check if there was an authenticated user on the server-side. If there was no authed user I would redirect to a login page.\n\nI then realised I could make use of the resolve feature on the $routeProvider to check whether the user was present and if not, redirect. In relation to the latter point, this was achieved using the following:\n\n    $rootScope.$on('$routeChangeError', function(){\n        $location.path('/login')\n    });\n\nThis works quite nicely however it's not immediately clear to me why this is necessary on the basis that the user should be attached to the $rootScope on the client-side and so I should be able to monitor whether or not there is an authenticated user without going to the server. One for a future tinkering perhaps.\n\n**Caching**\n\nOne problem that stumped me for some time was that in Internet Explorer 10, fetching data from the server appeared not to work as old data kept on appearing, even if a client-side input had resulted in the data changing.\n\nBeing a bit of a novice, it took a while to realise that the client was displaying cached data. After some digging, I found out that adding the following properties to the response headers would instruct the client-side not to cache results, meaning that fresh data would be displayed in each instance.\n\n    res.set('Cache-Control', 'no-cache, no-store');\n\n**Logging**\n\nNot Angular.js related, however, building the app gave me an appreciation for the art of logging. When attempting to login I was periodically faced with 502 Bad Gateway errors from Nginx. I think the periodic error as opposed to the consistent error is possibly the most frustrating especially for a beginner because it makes it that much harder to track down.\n\nAlthough I began to log errors arising from the Express app, and also with Nginx, this got me no closer to a solution. Eventually, I realised that because I was using Forever to keep the Express app up, there might be a solution within Forever's logs.\n\nSure enough, it became clear that the issue was with the MongoDB instance I was using throwing an error. Having identified the source of the problem I switched to a new instance and have had no problems since that point.\n\n**Passport.js**\n\nBeing a novice and also not wishing to reinvent the wheel, I initially used passport.js for authentication within Express. This worked like a charm however as in perhaps a lot of cases, it seemed ever so slightly magical. I appreciate that I could have dug into the underlying code but as I'm a beginner this was a little daunting.\n\nUsing Passport.js was great, however where I wanted to deviate from the functionality made available by passport things were a little tricky. I stumbled across an example of authentication on [Runnable](http://runnable.com/UTlPPF-f2W1TAAEY/login-auth-using-sessions-in-express-for-node-js-and-authentication). The 'authenticate' function in particular made a great deal more sense to me than the passport LocalStrategy example shown [here](http://passportjs.org/guide/username-password/).\n\nSpecifically, the usage of 'fn' as a callback to pass in either the error or the user seemed much clearer than the abstraction used by passport (It wasn't immediately clear to me where the 'done' callback was actually called - although I think this may be done internally with the user automatically added to 'req.user'). This is absolutely a reflection on my status as a beginner rather than passport however.\n\nConsequently, on the basis that my needs were relatively simple, I replaced passport with the authenticate function. I think all in all this has been working well for me thus far although I appreciate that passport can really come into its own when multiple authentication routes As a bonus, I have also been using the pattern of returning a function with either the error, or the result as a means of building up more complex functions by incorporating existing functions using this pattern.\n\n    // Function\n    function authenticate(name, pass, fn) {\n       User.find({name: name}, function(err, user){\n           if (err) { return fn(err);}\n           else  { return fn(null, user); }\n       })\n    }\n\n    // Usage\n    authenticate(\"username\", \"password\", function(err, user){\n        if (user){\n              req.session.regenerate(function(){\n                req.session.user = user;\n                res.status(200).send();\n              })\n          }\n          else {\n            res.status(401).send({message: \"Error\"})\n          }\n    }\n\n**Conclusion**\n\nAll in all, the development process was fairly smooth and I very much enjoy using Angular and being forced to compartmentalise functionality in separate controllers and services. As outlined above, there were some moments which resulted in long delays (and scouring of Stackoverflow of course) but I am pleased with the end result.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "92649b13efe9c051cf813305e5eefaeb",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Learnings from building a basic Angular.js app",
        "path": "/Learnings-from-building-a-basic-Angular.js-app",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nI have recently been tinkering with Angular.js to build a basic application called Instok. Although I haven't really scratched the surface when it comes to Angular.js, I definitely learned a good amount about the framework and thought I'd share that in a post:\n\n**Authentication**\n\nHaving worked with pure-server side authentication (in the sense that all authentication happened on the server, and if a request was successful there would be a redirect with a full page re-render) it was definitely a hurdle for me to manage authentication in Angular.\n\nThe main issue was that instead of there being a full page re-render on authentication, the server would notify the client that authentication was successful.\n\nHowever, initially I tried to stick as closely as possible to the existing server-side method as possible. This involved setting the user as a local variable (using app.locals in Express) which would be passed when the initial index.html template was rendered on the client side.\n\nHowever, this technique proved to be a little problematic for me on the basis that when a user logged out on the client-side, the change did not immediately follow through in the entirety of the app.\n\nSpecifically, conditional views using ng-show would continue to display as if the user was still logged in. I think this may have been solved with a full page re-render but on the basis that I was using ng-view to display the bulk of the app (with the ng-show elements sitting outside the ng-view), I didn't necessarily want to do this.\n\nI think I then read about an alternative which would be to create a service to fetch the authenticated user from the server on a successful authentication. As a result, when the user logs in, on a successful request, the server responds with a 200 status, and the client then subsequently requests the logged in user's details.\n\nOn a successful request, the user is then attached to the rootScope, and therefore accessible through the Angular app.\n\nAs a side note, I tried to simply send the authed user back with the login request, but for reasons I couldn't fathom this didn't work as desired. I also realise I should potentially use http interceptors to deal with the incoming requests, rather than waiting to deal with them in a service however at this stage I think I'm just pleased I've got authentication to work ok!\n\n**Restricting routes**\n\nInitially in each controller for a particular route that I wanted to restrict access to I would make a call to the server to check if there was an authenticated user on the server-side. If there was no authed user I would redirect to a login page.\n\nI then realised I could make use of the resolve feature on the $routeProvider to check whether the user was present and if not, redirect. In relation to the latter point, this was achieved using the following:\n\n    $rootScope.$on('$routeChangeError', function(){\n        $location.path('/login')\n    });\n\nThis works quite nicely however it's not immediately clear to me why this is necessary on the basis that the user should be attached to the $rootScope on the client-side and so I should be able to monitor whether or not there is an authenticated user without going to the server. One for a future tinkering perhaps.\n\n**Caching**\n\nOne problem that stumped me for some time was that in Internet Explorer 10, fetching data from the server appeared not to work as old data kept on appearing, even if a client-side input had resulted in the data changing.\n\nBeing a bit of a novice, it took a while to realise that the client was displaying cached data. After some digging, I found out that adding the following properties to the response headers would instruct the client-side not to cache results, meaning that fresh data would be displayed in each instance.\n\n    res.set('Cache-Control', 'no-cache, no-store');\n\n**Logging**\n\nNot Angular.js related, however, building the app gave me an appreciation for the art of logging. When attempting to login I was periodically faced with 502 Bad Gateway errors from Nginx. I think the periodic error as opposed to the consistent error is possibly the most frustrating especially for a beginner because it makes it that much harder to track down.\n\nAlthough I began to log errors arising from the Express app, and also with Nginx, this got me no closer to a solution. Eventually, I realised that because I was using Forever to keep the Express app up, there might be a solution within Forever's logs.\n\nSure enough, it became clear that the issue was with the MongoDB instance I was using throwing an error. Having identified the source of the problem I switched to a new instance and have had no problems since that point.\n\n**Passport.js**\n\nBeing a novice and also not wishing to reinvent the wheel, I initially used passport.js for authentication within Express. This worked like a charm however as in perhaps a lot of cases, it seemed ever so slightly magical. I appreciate that I could have dug into the underlying code but as I'm a beginner this was a little daunting.\n\nUsing Passport.js was great, however where I wanted to deviate from the functionality made available by passport things were a little tricky. I stumbled across an example of authentication on [Runnable](http://runnable.com/UTlPPF-f2W1TAAEY/login-auth-using-sessions-in-express-for-node-js-and-authentication). The 'authenticate' function in particular made a great deal more sense to me than the passport LocalStrategy example shown [here](http://passportjs.org/guide/username-password/).\n\nSpecifically, the usage of 'fn' as a callback to pass in either the error or the user seemed much clearer than the abstraction used by passport (It wasn't immediately clear to me where the 'done' callback was actually called - although I think this may be done internally with the user automatically added to 'req.user'). This is absolutely a reflection on my status as a beginner rather than passport however.\n\nConsequently, on the basis that my needs were relatively simple, I replaced passport with the authenticate function. I think all in all this has been working well for me thus far although I appreciate that passport can really come into its own when multiple authentication routes As a bonus, I have also been using the pattern of returning a function with either the error, or the result as a means of building up more complex functions by incorporating existing functions using this pattern.\n\n    // Function\n    function authenticate(name, pass, fn) {\n       User.find({name: name}, function(err, user){\n           if (err) { return fn(err);}\n           else  { return fn(null, user); }\n       })\n    }\n\n    // Usage\n    authenticate(\"username\", \"password\", function(err, user){\n        if (user){\n              req.session.regenerate(function(){\n                req.session.user = user;\n                res.status(200).send();\n              })\n          }\n          else {\n            res.status(401).send({message: \"Error\"})\n          }\n    }\n\n**Conclusion**\n\nAll in all, the development process was fairly smooth and I very much enjoy using Angular and being forced to compartmentalise functionality in separate controllers and services. As outlined above, there were some moments which resulted in long delays (and scouring of Stackoverflow of course) but I am pleased with the end result.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file",
      "internal": {
        "content": "---\npath: '/Moving-towards-object-oriented-JavaScript'\ntitle: 'Moving towards object oriented JavaScript'\n---\n\n        971 additions and 3,493 deletions\n\nThe above statistic from Github from the repository for one of my apps [Routebop](https://github.com/grabbeh/routebop) showing the changes to the repo following a few days of editing is gratifying to me<sup id=\"fnref1\">[1](#fn1)</sup>.\n\nWhilst as a beginner you would normally code to improve or build a new feature, a user of the site would not notice any change to the functionality of the site following the above changes.\n\nSo on the basis that you'd normally change code to alter functionality, what actually changed?\n\nWhen I initially built the site because I had a fear of cross-contamination of JS amongst different pages, and because I was (and still am in many ways) a beginner, I decided to place all the JavaScript necessary for each page in the page itself with no sharing of JS between pages at all. As functionality between pages is shared to an extent, this meant that there was a significant amount of duplication<sup id=\"fnref2\">[2](#fn2)</sup>.\n\nHowever, the extent of duplication meant that there was always a nagging feeling that switching from the JS-per-page approach to one using separate JS files would lead to a much cleaner approach and allow for an easier time in updating functionality in the future.\n\nWhen I decided to refactor the code I first selected the page which I felt had the most functionality that I could potentially share across other pages. Following this, still within the same page I split up functions where I could. For example, one function collects and converts markers and waypoints into a more basic form, POSTs to the server, and then responds with a success message.\n\nOn the basis that the POSTing to the server element would be repeated, I split out this functionality and put a small wrapper around it to pass through transaction specific arguments into the function as follows:\n\n    this.sendToServer = function(postdata, posturl, completefunction){\n    $.ajax({\n        url: posturl,\n        type: \"POST\",\n        contentType: \"application/json\",\n        processData: false,\n        data: JSON.stringify(postdata),\n        success: completefunction\n        });\n    };\n    this.sendToServer(postdata, \"/show\", function(data){\n        $('#result').html(data.message);\n        });\n    };\n\nThis way, the function could be re-used passing in different arguments depending on what was necessary in the circumstances. In respect of the 'completefunction' and as per the above I use an anonymous function when the function is actually called to specify what will happen when the POST request is successful (displaying a success message, or processing the data onto a map for example).\n\nFollowing this point, I then started work on a separate JavaScript file switching across functions from the page itself into the JS file. I adopted a rather timid approach to this initially, switching over a function or two, then making reference to them in the HTML file to ensure things were still working.\n\n**Design patterns you say?**\n\nI do have a copy of [Design Patterns](http://addyosmani.com/resources/essentialjsdesignpatterns/book/) by Addy Osmani on my bookshelf at home, however, on flipping through the book, I suspect the pattern I've used is somewhere between Constructor and the module pattern.\n\nEssentially, this means that to use the JavaScript I create an instance of the Constructor by using the 'new' keyword and then attach that to a variable when opening a particular page. I think in part this is inspired by Google Maps which uses the new keyword when instantiating a new map or map-related item ilke a marker or infowindow.\n\nAt the same time as creating a public interface using 'new', I also included local variables within the Constructor which are only able to be accessed by public methods on the instance. An example is as follows:\n\n    function Map(){\n        var mapmarkers = [];\n        this.returnMapMarkers = function(){\n        \treturn mapmarkers;\n        }; \n        this.addMarkersToMap = function(array){\n        // function to place marker on map & push into mapmarkersarray\n        };\n    };\n\n    // Instantiation\n\n    var map = new Map;\n\n    map.mapmarkers;\n    >> undefined\n\n    map.returnMapMarkers()\n    >> [ array of markers ]\n\nIn this way, the mapmarkers private variable can only be accessed and updated using public methods (as I understand it).<sup id=\"fnref3\">[3](#fn3)</sup>.\n\n**Limitations on code re-use**\n\nIn the process of refactoring the code, there were times when in the current state, I couldn't re-use the code across pages. At this point, I had to create new functions which although very similar in nature to existing functions performed slightly differently.\n\nThis was definitely a lazy way of doing things, and in future, I hope to do more work in stripping down functions into their component parts to ensure a greater ability to re-use functionality.\n\n**Separation of functionality**\n\nIn addition to the main map.js file I also created separate files to cover distinct functionality on the site. This includes image upload handling and geocoding. I think this is a fairly common practice. As part of this, I created a init() function which is then the only function called to add the functionality to the page, as it incorporates calls to all the necessary functions.\n\nIn summary, when it comes to code refactoring, I don't really know what I'm doing. However although the above may not be (i) the most efficient in terms of code re-use or (ii) implement a design pattern correctly, it is definitely a leap forward for me from the JS-per-page approach used previously.\n\nIn future I hope to use the code I've written to help me improve my usage of design patterns and write better JavaScript generally.\n\n<div class=\"footnotes\">\n\n* * *\n\n1.  Particularly on the basis that the total repo size was only 20k lines of code before the changes. [↩](#fnref1)\n\n2.  On the other hand, one slight benefit was that altering JS on one page would only affect the functionality on that page. This form of sand-boxing helped to provide comfort that making changes to the page on the basis that it would not break another page. [↩](#fnref2)\n\n3.  One point that does need addressing is that usually you would define static methods on the prototype of the Constructor rather than directly using 'this'. This is because by using prototype methods are automatically shared on all instances of the constructor, whereas with 'this' each method is defined afresh when a new instance is created with 'new'. I'll be updating this in the future (although in fairness multiple instances are not created on the site (for example only one 'Map' instance is created per page)). [↩](#fnref3)\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "4fadd4084a649312b442b977a4ddf3ff",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Moving towards object oriented JavaScript",
        "path": "/Moving-towards-object-oriented-JavaScript",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\n        971 additions and 3,493 deletions\n\nThe above statistic from Github from the repository for one of my apps [Routebop](https://github.com/grabbeh/routebop) showing the changes to the repo following a few days of editing is gratifying to me<sup id=\"fnref1\">[1](#fn1)</sup>.\n\nWhilst as a beginner you would normally code to improve or build a new feature, a user of the site would not notice any change to the functionality of the site following the above changes.\n\nSo on the basis that you'd normally change code to alter functionality, what actually changed?\n\nWhen I initially built the site because I had a fear of cross-contamination of JS amongst different pages, and because I was (and still am in many ways) a beginner, I decided to place all the JavaScript necessary for each page in the page itself with no sharing of JS between pages at all. As functionality between pages is shared to an extent, this meant that there was a significant amount of duplication<sup id=\"fnref2\">[2](#fn2)</sup>.\n\nHowever, the extent of duplication meant that there was always a nagging feeling that switching from the JS-per-page approach to one using separate JS files would lead to a much cleaner approach and allow for an easier time in updating functionality in the future.\n\nWhen I decided to refactor the code I first selected the page which I felt had the most functionality that I could potentially share across other pages. Following this, still within the same page I split up functions where I could. For example, one function collects and converts markers and waypoints into a more basic form, POSTs to the server, and then responds with a success message.\n\nOn the basis that the POSTing to the server element would be repeated, I split out this functionality and put a small wrapper around it to pass through transaction specific arguments into the function as follows:\n\n    this.sendToServer = function(postdata, posturl, completefunction){\n    $.ajax({\n        url: posturl,\n        type: \"POST\",\n        contentType: \"application/json\",\n        processData: false,\n        data: JSON.stringify(postdata),\n        success: completefunction\n        });\n    };\n    this.sendToServer(postdata, \"/show\", function(data){\n        $('#result').html(data.message);\n        });\n    };\n\nThis way, the function could be re-used passing in different arguments depending on what was necessary in the circumstances. In respect of the 'completefunction' and as per the above I use an anonymous function when the function is actually called to specify what will happen when the POST request is successful (displaying a success message, or processing the data onto a map for example).\n\nFollowing this point, I then started work on a separate JavaScript file switching across functions from the page itself into the JS file. I adopted a rather timid approach to this initially, switching over a function or two, then making reference to them in the HTML file to ensure things were still working.\n\n**Design patterns you say?**\n\nI do have a copy of [Design Patterns](http://addyosmani.com/resources/essentialjsdesignpatterns/book/) by Addy Osmani on my bookshelf at home, however, on flipping through the book, I suspect the pattern I've used is somewhere between Constructor and the module pattern.\n\nEssentially, this means that to use the JavaScript I create an instance of the Constructor by using the 'new' keyword and then attach that to a variable when opening a particular page. I think in part this is inspired by Google Maps which uses the new keyword when instantiating a new map or map-related item ilke a marker or infowindow.\n\nAt the same time as creating a public interface using 'new', I also included local variables within the Constructor which are only able to be accessed by public methods on the instance. An example is as follows:\n\n    function Map(){\n        var mapmarkers = [];\n        this.returnMapMarkers = function(){\n        \treturn mapmarkers;\n        }; \n        this.addMarkersToMap = function(array){\n        // function to place marker on map & push into mapmarkersarray\n        };\n    };\n\n    // Instantiation\n\n    var map = new Map;\n\n    map.mapmarkers;\n    >> undefined\n\n    map.returnMapMarkers()\n    >> [ array of markers ]\n\nIn this way, the mapmarkers private variable can only be accessed and updated using public methods (as I understand it).<sup id=\"fnref3\">[3](#fn3)</sup>.\n\n**Limitations on code re-use**\n\nIn the process of refactoring the code, there were times when in the current state, I couldn't re-use the code across pages. At this point, I had to create new functions which although very similar in nature to existing functions performed slightly differently.\n\nThis was definitely a lazy way of doing things, and in future, I hope to do more work in stripping down functions into their component parts to ensure a greater ability to re-use functionality.\n\n**Separation of functionality**\n\nIn addition to the main map.js file I also created separate files to cover distinct functionality on the site. This includes image upload handling and geocoding. I think this is a fairly common practice. As part of this, I created a init() function which is then the only function called to add the functionality to the page, as it incorporates calls to all the necessary functions.\n\nIn summary, when it comes to code refactoring, I don't really know what I'm doing. However although the above may not be (i) the most efficient in terms of code re-use or (ii) implement a design pattern correctly, it is definitely a leap forward for me from the JS-per-page approach used previously.\n\nIn future I hope to use the code I've written to help me improve my usage of design patterns and write better JavaScript generally.\n\n<div class=\"footnotes\">\n\n* * *\n\n1.  Particularly on the basis that the total repo size was only 20k lines of code before the changes. [↩](#fnref1)\n\n2.  On the other hand, one slight benefit was that altering JS on one page would only affect the functionality on that page. This form of sand-boxing helped to provide comfort that making changes to the page on the basis that it would not break another page. [↩](#fnref2)\n\n3.  One point that does need addressing is that usually you would define static methods on the prototype of the Constructor rather than directly using 'this'. This is because by using prototype methods are automatically shared on all instances of the constructor, whereas with 'this' each method is defined afresh when a new instance is created with 'new'. I'll be updating this in the future (although in fairness multiple instances are not created on the site (for example only one 'Map' instance is created per page)). [↩](#fnref3)\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md"
    },
    "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file >>> MarkdownRemark": {
      "id": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file >>> MarkdownRemark",
      "children": [],
      "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file",
      "internal": {
        "content": "---\npath: '/Digital-Ocean-VPS-Nginx-Express-apps'\ntitle: 'Digital Ocean VPS, Nginx and Express apps'\n---\n\nI recently started investigating the murky (at least for me) world of VPSs. I was previously hosting a few pet projects on Nodejitsu but although their service is excellent, the nature of my projects didn't really warrant using the platform.\n\nAt the same time, I was interested in learning more about using linux commands and investigating how straightforward it was for a beginner to get Express apps running on a VPS and accessible via a specified subdomain.\n\n[Digital Ocean](http://digitalocean.com) provides a basic option at $5 per month and I spun up an instance running Ubuntu 12.04 based in Amsterdam no less.\n\nYou'll access your VPS by using a SSH client. As I'm on Windows I use [PuTTY](http://www.chiark.greenend.org.uk/%7Esgtatham/putty/). Through this you'll input your login details for the VPS and you should be able to start on the road to getting your Express app running.\n\n[Nginx](http://wiki.nginx.org/Main) is an open source http/reverse proxy server software and is being increasingly used on the basis that it offers simplified but powerful functionality for running servers in comparison to Apache (as I understand it at least!).\n\nThe first steps was to get Nginx running. This was fairly straightforward and I followed the steps in [Nginx HTTP Server](http://www.packtpub.com/nginx-http-server/book) by Clement Nedelcu. Nginx runs by using a central configuration file, but you can incorporate other conf files with the simple use of 'include'. On my installation the conf files were located in the following folder /usr/local/nginx/conf/ on the VPS.\n\nSo following installation I had a basic http server up and running serving a index.html file at grabeh.net (adding a domain through Digital Ocean and updating the nameservers to point at the VPS was simple enough).\n\n**_Installing node.js and your Express app_**\n\nThe next step was to identify how to get Express apps running on the VPS. Installing node.js itself was obviously key!\n\nThe most straightforward way I identified was the following:\n\n*   apt-get install python-software-properties\n*   apt-add-repository ppa:chris-lea/node.js\n*   apt-get update\n*   apt-get install nodejs\n\nAfter this point I was able to type in 'node' and get access to the REPL. Typing in 2 + 2 did indeed give me 4 which was a pleasure to see (particularly owing to my deficient maths skills). As a bonus, you'll also get npm for package control.\n\nThe next step was to get a small Express app running on the VPS. The easiest way I found was to git clone a basic app into the VPS. You can use the one [here](http://github.com/Grabbeh/express-hello-world) on Github if you want. (Using apt-get install git-core will give you access to git commands).\n\nThen simply 'npm install' to install the Express dependency. After that 'node app' should have the app running on port 3000.\n\nAs you will see using node app means the app is running in the foreground which means we cannot do anything else on the command line whilst the app is running. This simply will not do!\n\nI recalled a while ago reading about Nodejitsu's Forever tool which allows you to set a node app running in the background. This [link](http://blog.nodejitsu.com/keep-a-nodejs-server-up-with-forever) on Nodejitsu's site provides step-by-step instructions, however basically just use 'npm install forever -g' and then in your app's directory you can use 'forever start app.js' and your app will be running in the background. If you're planning on running multiple apps you may want to remain the app.js file to be more descriptive.\n\nThis is because 'forever list' will specify the apps running and for me things got confusing when I was using app.js for all apps.\n\n**_Getting your Express app displaying on a subdomain_**\n\nThe next step was to determine how to get the app to display via a subdomain on grabeh.net.\n\nA brief visit to Stackoverflow showed the way, and it wasn't long before the Nginx 'proxy_pass' and 'upstream' directives were identified as being necessary via this [Stackoverflow question](http://stackoverflow.com/questions/5009324/node-js-nginx-and-now).\n\nAfter some tinkering I used the following configuration file to specify port 3000 as the upstream location for the Express app, and then using proxy_pass and proxy_set_... to specify what should happen with requests to, in this case, helloworld.grabeh.net.\n```\n      worker_processes 1;\n\n      events {\n        worker_connections 1024;\n      }\n      http {\n\n          include       mime.types;\n          default_type  application/octet-stream;\n          sendfile      on;\n          tcp_nopush    on;\n\n      # specify the location of the Express app you want to serve up\n\n      upstream helloworld {\n        server localhost:3000;\n      }\n\n      # calls to www.grabeh.net will be rewritten to grabeh.net\n\n      server {\n        listen 80;\n          server_name www.grabeh.net *.grabeh.net;\n          rewrite ^(.*) http://grabeh.net$1 permanent;\n      } \n\n      # specify what will happen when a request to helloworld.[your domain] is made. \n      # Here we are proxying the Express app through.\n\n      server {\n        listen 80;\n        server_name helloworld.grabeh.net;\n\n        location / {\n          try_files $uri @helloworld;\n      }\n\n        location @helloworld {\n          proxy_set_header X-Real-IP $remote_addr;\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header Host $proxy_host;\n          proxy_set_header X-NginX-Proxy true;\n          proxy_pass http://helloworld;\n          }\n      }\n\n      # basic element where we're sending index.html for requests to grabeh.net/\n      server {\n        listen 80; \n        server_name grabeh.net;\n\n        location / {\n          root html/home;\n          index index.html index.htm;\n          }  \n          }\n      }\n```\nIf you use this you'll obviously have to update the domain name 'grabeh.net' to your own domain.\n\nTesting your .conf before sending it live is important. If I'm making any changes to nginx.conf I first use 'cp nginx.conf test.conf' and make changes to test.conf rather than the live file. Testing the file is done by ./nginx -t -c [location of test.conf]. If tests pass, then using 'mv test.conf nginx.conf' will switch in the new conf for the existing one.\n\nAfter switching in the modified .conf file using './nginx -s reload' should result in 'Hello World' showing when you navigate to 'helloworld.[yourdomain].[tld].\n\nHopefully the above or at least parts of it are useful. It's always good for me to get thoughts down to help cement my understanding. I'm still getting to grips with Nginx and whilst there was lots of good information on Digital Ocean's site and Stackoverflow of course, there didn't seem to be a full step-by-step guide to the entire process.\n\n",
        "type": "MarkdownRemark",
        "contentDigest": "f18cee0d8ae4ae81f69aa50c42e8efff",
        "owner": "gatsby-transformer-remark"
      },
      "frontmatter": {
        "title": "Digital Ocean VPS, Nginx and Express apps",
        "path": "/Digital-Ocean-VPS-Nginx-Express-apps",
        "_PARENT": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file",
        "parent": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file"
      },
      "excerpt": "",
      "rawMarkdownBody": "\nI recently started investigating the murky (at least for me) world of VPSs. I was previously hosting a few pet projects on Nodejitsu but although their service is excellent, the nature of my projects didn't really warrant using the platform.\n\nAt the same time, I was interested in learning more about using linux commands and investigating how straightforward it was for a beginner to get Express apps running on a VPS and accessible via a specified subdomain.\n\n[Digital Ocean](http://digitalocean.com) provides a basic option at $5 per month and I spun up an instance running Ubuntu 12.04 based in Amsterdam no less.\n\nYou'll access your VPS by using a SSH client. As I'm on Windows I use [PuTTY](http://www.chiark.greenend.org.uk/%7Esgtatham/putty/). Through this you'll input your login details for the VPS and you should be able to start on the road to getting your Express app running.\n\n[Nginx](http://wiki.nginx.org/Main) is an open source http/reverse proxy server software and is being increasingly used on the basis that it offers simplified but powerful functionality for running servers in comparison to Apache (as I understand it at least!).\n\nThe first steps was to get Nginx running. This was fairly straightforward and I followed the steps in [Nginx HTTP Server](http://www.packtpub.com/nginx-http-server/book) by Clement Nedelcu. Nginx runs by using a central configuration file, but you can incorporate other conf files with the simple use of 'include'. On my installation the conf files were located in the following folder /usr/local/nginx/conf/ on the VPS.\n\nSo following installation I had a basic http server up and running serving a index.html file at grabeh.net (adding a domain through Digital Ocean and updating the nameservers to point at the VPS was simple enough).\n\n**_Installing node.js and your Express app_**\n\nThe next step was to identify how to get Express apps running on the VPS. Installing node.js itself was obviously key!\n\nThe most straightforward way I identified was the following:\n\n*   apt-get install python-software-properties\n*   apt-add-repository ppa:chris-lea/node.js\n*   apt-get update\n*   apt-get install nodejs\n\nAfter this point I was able to type in 'node' and get access to the REPL. Typing in 2 + 2 did indeed give me 4 which was a pleasure to see (particularly owing to my deficient maths skills). As a bonus, you'll also get npm for package control.\n\nThe next step was to get a small Express app running on the VPS. The easiest way I found was to git clone a basic app into the VPS. You can use the one [here](http://github.com/Grabbeh/express-hello-world) on Github if you want. (Using apt-get install git-core will give you access to git commands).\n\nThen simply 'npm install' to install the Express dependency. After that 'node app' should have the app running on port 3000.\n\nAs you will see using node app means the app is running in the foreground which means we cannot do anything else on the command line whilst the app is running. This simply will not do!\n\nI recalled a while ago reading about Nodejitsu's Forever tool which allows you to set a node app running in the background. This [link](http://blog.nodejitsu.com/keep-a-nodejs-server-up-with-forever) on Nodejitsu's site provides step-by-step instructions, however basically just use 'npm install forever -g' and then in your app's directory you can use 'forever start app.js' and your app will be running in the background. If you're planning on running multiple apps you may want to remain the app.js file to be more descriptive.\n\nThis is because 'forever list' will specify the apps running and for me things got confusing when I was using app.js for all apps.\n\n**_Getting your Express app displaying on a subdomain_**\n\nThe next step was to determine how to get the app to display via a subdomain on grabeh.net.\n\nA brief visit to Stackoverflow showed the way, and it wasn't long before the Nginx 'proxy_pass' and 'upstream' directives were identified as being necessary via this [Stackoverflow question](http://stackoverflow.com/questions/5009324/node-js-nginx-and-now).\n\nAfter some tinkering I used the following configuration file to specify port 3000 as the upstream location for the Express app, and then using proxy_pass and proxy_set_... to specify what should happen with requests to, in this case, helloworld.grabeh.net.\n```\n      worker_processes 1;\n\n      events {\n        worker_connections 1024;\n      }\n      http {\n\n          include       mime.types;\n          default_type  application/octet-stream;\n          sendfile      on;\n          tcp_nopush    on;\n\n      # specify the location of the Express app you want to serve up\n\n      upstream helloworld {\n        server localhost:3000;\n      }\n\n      # calls to www.grabeh.net will be rewritten to grabeh.net\n\n      server {\n        listen 80;\n          server_name www.grabeh.net *.grabeh.net;\n          rewrite ^(.*) http://grabeh.net$1 permanent;\n      } \n\n      # specify what will happen when a request to helloworld.[your domain] is made. \n      # Here we are proxying the Express app through.\n\n      server {\n        listen 80;\n        server_name helloworld.grabeh.net;\n\n        location / {\n          try_files $uri @helloworld;\n      }\n\n        location @helloworld {\n          proxy_set_header X-Real-IP $remote_addr;\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header Host $proxy_host;\n          proxy_set_header X-NginX-Proxy true;\n          proxy_pass http://helloworld;\n          }\n      }\n\n      # basic element where we're sending index.html for requests to grabeh.net/\n      server {\n        listen 80; \n        server_name grabeh.net;\n\n        location / {\n          root html/home;\n          index index.html index.htm;\n          }  \n          }\n      }\n```\nIf you use this you'll obviously have to update the domain name 'grabeh.net' to your own domain.\n\nTesting your .conf before sending it live is important. If I'm making any changes to nginx.conf I first use 'cp nginx.conf test.conf' and make changes to test.conf rather than the live file. Testing the file is done by ./nginx -t -c [location of test.conf]. If tests pass, then using 'mv test.conf nginx.conf' will switch in the new conf for the existing one.\n\nAfter switching in the modified .conf file using './nginx -s reload' should result in 'Hello World' showing when you navigate to 'helloworld.[yourdomain].[tld].\n\nHopefully the above or at least parts of it are useful. It's always good for me to get thoughts down to help cement my understanding. I'm still getting to grips with Nginx and whilst there was lots of good information on Digital Ocean's site and Stackoverflow of course, there didn't seem to be a full step-by-step guide to the entire process.\n\n",
      "fileAbsolutePath": "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md"
    },
    "SitePage /Adventures-with-CouchDB-Nano-and-Pjax": {
      "layout": "index",
      "jsonName": "adventures-with-couch-db-nano-and-pjax.json",
      "internalComponentName": "ComponentAdventuresWithCouchDbNanoAndPjax",
      "path": "/Adventures-with-CouchDB-Nano-and-Pjax",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Adventures-with-CouchDB-Nano-and-Pjax",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "b15bc64e0c31ecdde0b456c8d8590306",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Online-terms-better-with-notice": {
      "layout": "index",
      "jsonName": "online-terms-better-with-notice.json",
      "internalComponentName": "ComponentOnlineTermsBetterWithNotice",
      "path": "/Online-terms-better-with-notice",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Online-terms-better-with-notice",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "a6324b0f2741be5d05640ece86efb082",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /A-comparison-of-drafting-legal-documents-vs-coding": {
      "layout": "index",
      "jsonName": "a-comparison-of-drafting-legal-documents-vs-coding.json",
      "internalComponentName": "ComponentAComparisonOfDraftingLegalDocumentsVsCoding",
      "path": "/A-comparison-of-drafting-legal-documents-vs-coding",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /A-comparison-of-drafting-legal-documents-vs-coding",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "0a2110701c8605355a11d975c23ea4a8",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Refactoring-from-jQuery-to-Angular.js": {
      "layout": "index",
      "jsonName": "refactoring-from-j-query-to-angular-js.json",
      "internalComponentName": "ComponentRefactoringFromJQueryToAngularJs",
      "path": "/Refactoring-from-jQuery-to-Angular.js",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Refactoring-from-jQuery-to-Angular.js",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "85fbbe9691821b25f7ab76f807d81220",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean": {
      "layout": "index",
      "jsonName": "setting-up-https-with-express-apps-using-nginx-and-digital-ocean.json",
      "internalComponentName": "ComponentSettingUpHttpsWithExpressAppsUsingNginxAndDigitalOcean",
      "path": "/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "b07abd4c4e8185a0cce6e5d31be0c6ae",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes": {
      "layout": "index",
      "jsonName": "steps-to-improve-unity-ubuntu-on-chromebook-crouton-for-developer-purposes.json",
      "internalComponentName": "ComponentStepsToImproveUnityUbuntuOnChromebookCroutonForDeveloperPurposes",
      "path": "/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "7e553761a4fee64b422e1791dd59fc7b",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /The-journey-from-curious-outsider-to-beginner": {
      "layout": "index",
      "jsonName": "the-journey-from-curious-outsider-to-beginner.json",
      "internalComponentName": "ComponentTheJourneyFromCuriousOutsiderToBeginner",
      "path": "/The-journey-from-curious-outsider-to-beginner",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /The-journey-from-curious-outsider-to-beginner",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "2c04202930c3ae544259e08503890346",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js": {
      "layout": "index",
      "jsonName": "automated-publishing-on-a-vps-using-draftin-webhooks-and-node-js.json",
      "internalComponentName": "ComponentAutomatedPublishingOnAVpsUsingDraftinWebhooksAndNodeJs",
      "path": "/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "9988b3c7d4e7828328ddbf0aa9658bfc",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /The-myth-of-mandatory-trade-mark-enforcement": {
      "layout": "index",
      "jsonName": "the-myth-of-mandatory-trade-mark-enforcement.json",
      "internalComponentName": "ComponentTheMythOfMandatoryTradeMarkEnforcement",
      "path": "/The-myth-of-mandatory-trade-mark-enforcement",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /The-myth-of-mandatory-trade-mark-enforcement",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "c66acec1196cd83d5bccf7d9e779336c",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Image-uploads-and-resizing-with-Transloadit": {
      "layout": "index",
      "jsonName": "image-uploads-and-resizing-with-transloadit.json",
      "internalComponentName": "ComponentImageUploadsAndResizingWithTransloadit",
      "path": "/Image-uploads-and-resizing-with-Transloadit",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Image-uploads-and-resizing-with-Transloadit",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "2bb0876fd40be02f2afa5c9c1e9bc969",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Learnings-from-building-a-basic-Angular.js-app": {
      "layout": "index",
      "jsonName": "learnings-from-building-a-basic-angular-js-app.json",
      "internalComponentName": "ComponentLearningsFromBuildingABasicAngularJsApp",
      "path": "/Learnings-from-building-a-basic-Angular.js-app",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Learnings-from-building-a-basic-Angular.js-app",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "93809a9e6068ba40a0bd025b1d9c601b",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Moving-towards-object-oriented-JavaScript": {
      "layout": "index",
      "jsonName": "moving-towards-object-oriented-java-script.json",
      "internalComponentName": "ComponentMovingTowardsObjectOrientedJavaScript",
      "path": "/Moving-towards-object-oriented-JavaScript",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Moving-towards-object-oriented-JavaScript",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "ec1b9b40ab3045a1235aa837b79d2ede",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /Digital-Ocean-VPS-Nginx-Express-apps": {
      "layout": "index",
      "jsonName": "digital-ocean-vps-nginx-express-apps.json",
      "internalComponentName": "ComponentDigitalOceanVpsNginxExpressApps",
      "path": "/Digital-Ocean-VPS-Nginx-Express-apps",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "componentChunkName": "component---src-templates-post-template-js",
      "context": {},
      "pluginCreator___NODE": "Plugin default-site-plugin",
      "pluginCreatorId": "Plugin default-site-plugin",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/templates/postTemplate.js",
      "id": "SitePage /Digital-Ocean-VPS-Nginx-Express-apps",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "a81499c98cae77efb47158862b14ca0b",
        "description": "Your site's \"gatsby-node.js\"",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /404/": {
      "layout": "index",
      "jsonName": "404.json",
      "internalComponentName": "Component404",
      "path": "/404/",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/404.js",
      "componentChunkName": "component---src-pages-404-js",
      "context": {},
      "pluginCreator___NODE": "Plugin component-page-creator",
      "pluginCreatorId": "Plugin component-page-creator",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/404.js",
      "id": "SitePage /404/",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "02cc1a3d549ffb94cd85d72940a43893",
        "description": "Plugin component-page-creator",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /": {
      "layout": "index",
      "jsonName": "index.json",
      "internalComponentName": "ComponentIndex",
      "path": "/",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/index.js",
      "componentChunkName": "component---src-pages-index-js",
      "context": {},
      "pluginCreator___NODE": "Plugin component-page-creator",
      "pluginCreatorId": "Plugin component-page-creator",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/index.js",
      "id": "SitePage /",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "0d011136870c60cb00c3c34c03283fa7",
        "description": "Plugin component-page-creator",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /posts/": {
      "layout": "index",
      "jsonName": "posts.json",
      "internalComponentName": "ComponentPosts",
      "path": "/posts/",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/posts.js",
      "componentChunkName": "component---src-pages-posts-js",
      "context": {},
      "pluginCreator___NODE": "Plugin component-page-creator",
      "pluginCreatorId": "Plugin component-page-creator",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/posts.js",
      "id": "SitePage /posts/",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "4ee81f942679028e56579a318458a65d",
        "description": "Plugin component-page-creator",
        "owner": "internal-data-bridge"
      }
    },
    "SitePage /404.html": {
      "layout": "index",
      "jsonName": "404-html.json",
      "internalComponentName": "Component404Html",
      "path": "/404.html",
      "component": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/404.js",
      "componentChunkName": "component---src-pages-404-js",
      "context": {},
      "pluginCreator___NODE": "Plugin prod-404",
      "pluginCreatorId": "Plugin prod-404",
      "componentPath": "/mnt/c/Users/mbg/Documents/grabeh.net/src/pages/404.js",
      "id": "SitePage /404.html",
      "parent": "SOURCE",
      "children": [],
      "internal": {
        "type": "SitePage",
        "contentDigest": "29edbd0b714dc22c2c264a0272501e6d",
        "description": "Plugin prod-404",
        "owner": "internal-data-bridge"
      }
    }
  },
  "status": {
    "plugins": {},
    "PLUGINS_HASH": "74bde82b372c71b8097d35fad0d6eed7"
  },
  "componentDataDependencies": {
    "nodes": {
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Online-terms-better-with-notice.md absPath of file >>> MarkdownRemark": [
        "/Online-terms-better-with-notice"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Moving-towards-object-oriented-JavaScript.md absPath of file >>> MarkdownRemark": [
        "/Moving-towards-object-oriented-JavaScript"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Adventures-with-CouchDB-Nano-and-Pjax.md absPath of file >>> MarkdownRemark": [
        "/Adventures-with-CouchDB-Nano-and-Pjax"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/A-comparison-of-drafting-legal-documents-vs-coding.md absPath of file >>> MarkdownRemark": [
        "/A-comparison-of-drafting-legal-documents-vs-coding"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Refactoring-from-jQuery-to-Angular.js.md absPath of file >>> MarkdownRemark": [
        "/Refactoring-from-jQuery-to-Angular.js"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean.md absPath of file >>> MarkdownRemark": [
        "/Setting-up-HTTPS-with-Express-Apps-using-Nginx-and-Digital-Ocean"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes.md absPath of file >>> MarkdownRemark": [
        "/Steps-to-improve-Unity-Ubuntu-on-Chromebook-Crouton-for-developer-purposes"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-journey-from-curious-outsider-to-beginner.md absPath of file >>> MarkdownRemark": [
        "/The-journey-from-curious-outsider-to-beginner"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js.md absPath of file >>> MarkdownRemark": [
        "/Automated-publishing-on-a-VPS-using-Draftin-webhooks-and-Node.js"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/The-myth-of-mandatory-trade-mark-enforcement.md absPath of file >>> MarkdownRemark": [
        "/The-myth-of-mandatory-trade-mark-enforcement"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Image-uploads-and-resizing-with-Transloadit.md absPath of file >>> MarkdownRemark": [
        "/Image-uploads-and-resizing-with-Transloadit"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Learnings-from-building-a-basic-Angular.js-app.md absPath of file >>> MarkdownRemark": [
        "/Learnings-from-building-a-basic-Angular.js-app"
      ],
      "/mnt/c/Users/mbg/Documents/grabeh.net/markdown/Digital-Ocean-VPS-Nginx-Express-apps.md absPath of file >>> MarkdownRemark": [
        "/Digital-Ocean-VPS-Nginx-Express-apps"
      ],
      "Site": [
        "/",
        "/posts/"
      ]
    },
    "connections": {
      "SitePage": [
        "/dev-404-page/"
      ]
    }
  }
}